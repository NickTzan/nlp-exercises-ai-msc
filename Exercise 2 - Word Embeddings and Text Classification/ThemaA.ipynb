{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercise A: Word Embeddings\n",
        "#### Tzanis Nikolaos mtn2217"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YXV4cEaLOEQY"
      },
      "source": [
        "Firstly, the word2vec model is imported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1bm7CBpKsvJ",
        "outputId": "c50cf663-8bb8-4c15-c98d-b299b8459664"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "w2v_model = api.load(\"word2vec-google-news-300\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, the GloVe model is imported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
          ]
        }
      ],
      "source": [
        "glove_model = api.load('glove-wiki-gigaword-300')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "C6DhKfi5OMOF"
      },
      "source": [
        "Next, we create a function that will return the 10 closest words to a word of our choice using the model of our choice. The same function will be used in Word2Vec and in GloVe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def closestWords(word, model):\n",
        "    if word in model.key_to_index:\n",
        "        closest_words = model.most_similar(positive=[word], topn=10)\n",
        "        return_list = []\n",
        "        for word in closest_words:\n",
        "            return_list.append(word[0])\n",
        "        return return_list\n",
        "    else:\n",
        "        return []"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calling the above function we find the 10 closest words to each of the required words for the first question of the exercise, starting from the Word2Vec model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 10 closest words to the word car according to the Word2Vec model are: ['vehicle', 'cars', 'SUV', 'minivan', 'truck', 'Car', 'Ford_Focus', 'Honda_Civic', 'Jeep', 'pickup_truck']\n",
            "The 10 closest words to the word jaguar according to the Word2Vec model are: ['jaguars', 'Macho_B', 'panther', 'lynx', 'rhino', 'lizard', 'tapir', 'tiger', 'leopard', 'Florida_panther']\n",
            "The 10 closest words to the word Jaguar according to the Word2Vec model are: ['Land_Rover', 'Aston_Martin', 'Mercedes', 'Porsche', 'BMW', 'Bentley_Arnage', 'XF_sedan', 'Audi', 'Jaguar_XF', 'XJ_saloon']\n",
            "The 10 closest words to the word facebook according to the Word2Vec model are: ['Facebook', 'FaceBook', 'twitter', 'myspace', 'Twitter', 'twitter_facebook', 'Facebook.com', 'myspace_facebook', 'facebook_twitter', 'linkedin']\n"
          ]
        }
      ],
      "source": [
        "requested_words = ['car', 'jaguar', 'Jaguar', 'facebook']\n",
        "\n",
        "for word in requested_words:\n",
        "    print(f\"The 10 closest words to the word {word} according to the Word2Vec model are:\", closestWords(word, w2v_model))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we check the same words for the GloVe model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 10 closest words to the word car according to the GloVe model are: ['cars', 'vehicle', 'truck', 'driver', 'driving', 'vehicles', 'motorcycle', 'automobile', 'parked', 'drivers']\n",
            "The 10 closest words to the word jaguar according to the GloVe model are: ['rover', 'bmw', 'mercedes', 'sepecat', 'mustang', 'lexus', 'volvo', 'cosworth', 'xk', 'maserati']\n",
            "The 10 closest words to the word Jaguar according to the GloVe model are: []\n",
            "The 10 closest words to the word facebook according to the GloVe model are: ['twitter', 'myspace', 'youtube', 'blog', 'linkedin', 'google', 'website', 'web', 'blogs', 'networking']\n"
          ]
        }
      ],
      "source": [
        "for word in requested_words:\n",
        "    print(f\"The 10 closest words to the word {word} according to the GloVe model are:\", closestWords(word, glove_model))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the next part we create a function to check the common words for each word for each model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def commonWords(word, model1, model2):\n",
        "    common_words = []\n",
        "    closest_words_model1 = closestWords(word, model1)\n",
        "    closest_words_model2 = closestWords(word, model2)\n",
        "    for test_word in closest_words_model1:\n",
        "        if test_word in closest_words_model2:\n",
        "            common_words.append(test_word)\n",
        "    return common_words"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we call this function to find the common words for each of the requested words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The common words for the word car between the Word2Vec and the GloVe models are: ['vehicle', 'cars', 'truck']\n",
            "The common words for the word jaguar between the Word2Vec and the GloVe models are: []\n",
            "The common words for the word Jaguar between the Word2Vec and the GloVe models are: []\n",
            "The common words for the word facebook between the Word2Vec and the GloVe models are: ['twitter', 'myspace', 'linkedin']\n"
          ]
        }
      ],
      "source": [
        "for word in requested_words:\n",
        "    print(f'The common words for the word {word} between the Word2Vec and the GloVe models are:', commonWords(word, w2v_model, glove_model))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see there are 3 common words in the top 10 between the 2 models for the word 'car' and also 3 for the word 'facebook'. The word jaguar has different top 10 closest words in the 2 models."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 2\n",
        "For the next question we have to repeat the same process for 4 words of our choice. I personally chose the words 'nick', 'dog', 'line' and 'class'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "random_words = ['nick', 'dog', 'line', 'class']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testing the Word2Vec model first:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 10 closest words to the word nick according to the Word2Vec model are: ['mills_Remo_rubik', 'knick', 'nicked', 'Morgs', 'Haydos', 'sighter', 'Swanny', 'nicking', 'wellied', 'tonking']\n",
            "The 10 closest words to the word dog according to the Word2Vec model are: ['dogs', 'puppy', 'pit_bull', 'pooch', 'cat', 'golden_retriever', 'German_shepherd', 'Rottweiler', 'beagle', 'pup']\n",
            "The 10 closest words to the word line according to the Word2Vec model are: ['lines', 'homez.##/telenews/www/wp-content/plugins/wp-postviews/wp-p', 'coach_George_Yarno', 'httpdocs_wp_includes_rss.php', 'Line', 'coach_Bob_Palcic', 'line.The', 'home/content/c/#/#/c#####/html/libraries/joomla/applicatio', '###kV_overhead', 'generic_cialis_cialis']\n",
            "The 10 closest words to the word class according to the Word2Vec model are: ['classes', 'classs', 'Faithfully_Fit_exercise', 'Class', 'Ramla_mixed', 'grade', 'middle', 'IKON_integrates', 'runic_setup_signifies', 'royalists_wealthy']\n"
          ]
        }
      ],
      "source": [
        "for word in random_words:\n",
        "    print(f\"The 10 closest words to the word {word} according to the Word2Vec model are:\", closestWords(word, w2v_model))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And then the GloVe model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 10 closest words to the word nick according to the GloVe model are: ['greg', 'faldo', 'tom', 'matt', 'chris', 'clegg', 'phil', 'watson', 'ryan', 'johnny']\n",
            "The 10 closest words to the word dog according to the GloVe model are: ['dogs', 'cat', 'pet', 'puppy', 'hound', 'horse', 'animal', 'cats', 'canine', 'pets']\n",
            "The 10 closest words to the word line according to the GloVe model are: ['lines', 'running', 'railway', 'along', 'trains', 'rail', 'end', 'same', 'ran', 'up']\n",
            "The 10 closest words to the word class according to the GloVe model are: ['classes', 'type', 'school', 'grade', 'students', 'same', 'graduating', 'locomotives', 'ordinary', 'elite']\n"
          ]
        }
      ],
      "source": [
        "for word in random_words:\n",
        "    print(f\"The 10 closest words to the word {word} according to the GloVe model are:\", closestWords(word, glove_model))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the common words between the top 10 for the 2 models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The common words for the word nick between the Word2Vec and the GloVe models are: []\n",
            "The common words for the word dog between the Word2Vec and the GloVe models are: ['dogs', 'puppy', 'cat']\n",
            "The common words for the word line between the Word2Vec and the GloVe models are: ['lines']\n",
            "The common words for the word class between the Word2Vec and the GloVe models are: ['classes', 'grade']\n"
          ]
        }
      ],
      "source": [
        "for word in random_words:\n",
        "    print(f'The common words for the word {word} between the Word2Vec and the GloVe models are:', commonWords(word, w2v_model, glove_model))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 3\n",
        "First, let's explore the 10 closest words to the word 'student' using the function we created earlier. For the word2vec model, these words are:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 10 closest words to the word 'student' according to the Word2Vec model are: ['students', 'Student', 'teacher', 'stu_dent', 'faculty', 'school', 'undergraduate', 'university', 'undergraduates', 'semester']\n"
          ]
        }
      ],
      "source": [
        "print(f\"The 10 closest words to the word 'student' according to the Word2Vec model are:\", closestWords('student', w2v_model))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And for the GloVe model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 10 closest words to the word 'student' according to the GloVe model are: ['students', 'teacher', 'graduate', 'school', 'college', 'undergraduate', 'faculty', 'university', 'academic', 'campus']\n"
          ]
        }
      ],
      "source": [
        "print(f\"The 10 closest words to the word 'student' according to the GloVe model are:\", closestWords('student', glove_model))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, many of the above results are related to university or college students. If we have to filter these results for students in college (or university) we have to add this at the function call as 'negative='college'. Here's the modified function that allows to choose excluded words or more positive words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "def closestWordsFiltered(positive_words, negative_words, model):\n",
        "    if all(word not in model.key_to_index for word in positive_words + negative_words):\n",
        "        return []\n",
        "    else:\n",
        "        closest_words = model.most_similar(positive=positive_words, negative=negative_words, topn=10)\n",
        "        return_list = []\n",
        "        for word in closest_words:\n",
        "            return_list.append(word[0])\n",
        "        return return_list\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calling this new function we can now get the 10 closest words to the word student (not in university) with the word2vec model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 10 closest words to the word 'student' excluding the words related to university students according to the Word2Vec model are: ['sixth_grader', 'seventh_grader', '8th_grader', 'eighth_grader', 'grader', 'kindergartner', 'kindergartener', 'Kindergartner', 'teen', 'middle_schooler']\n"
          ]
        }
      ],
      "source": [
        "print(f\"The 10 closest words to the word 'student' excluding the words related to university students according to the Word2Vec model are:\", closestWordsFiltered(positive_words=['student'], negative_words=['university'], model=w2v_model))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And then for the GloVe model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 10 closest words to the word 'student' excluding the words related to university students according to the GloVe model are: ['15-year', '16-year', '17-year', '14-year', '13-year-old', '14-year-old', '9-year', '16-year-old', '15-year-old', '12-year-old']\n"
          ]
        }
      ],
      "source": [
        "print(f\"The 10 closest words to the word 'student' excluding the words related to university students according to the GloVe model are:\", closestWordsFiltered(positive_words=['student'], negative_words=['university'], model=glove_model))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now if we want to exclude the results for students in elementary, middle or high school, that means that we have to add those 3 words to the negative_words list of just simply add the word 'university' to the positive words list. Here's the result with the word2vec model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 10 closest words to the word 'student' excluding the words related to university students according to the Word2Vec model are: ['faculty', 'students', 'undergraduate', 'campus', 'undergraduates', 'academic', 'college', 'professors', 'unversity', 'univeristy']\n"
          ]
        }
      ],
      "source": [
        "print(f\"The 10 closest words to the word 'student' excluding the words related to university students according to the Word2Vec model are:\", closestWordsFiltered(positive_words=['student', 'university'], negative_words=[], model=w2v_model))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Doing the same for the GloVe model we get this result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The 10 closest words to the word 'student' excluding the words related to university students according to the GloVe model are: ['graduate', 'students', 'college', 'faculty', 'campus', 'professor', 'harvard', 'school', 'undergraduate', 'universities']\n"
          ]
        }
      ],
      "source": [
        "print(f\"The 10 closest words to the word 'student' excluding the words related to university students according to the GloVe model are:\", closestWordsFiltered(positive_words=['student', 'university'], negative_words=[], model=glove_model))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 4"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the function we created earlier we now find the result of the requested equations. For the Word2Vec model the results are:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['queen', 'monarch']"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#for king - man + woman = ?\n",
        "closestWordsFiltered(positive_words=['king', 'woman'], negative_words=['man'], model=w2v_model)[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Japan', 'Japanese']"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#for France - Paris + Tokyo = ?\n",
        "closestWordsFiltered(positive_words=['France', 'Tokyo'], negative_words=['Paris'], model=w2v_model)[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['oak_trees', 'vines']"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#for trees - apples + grapes = ?\n",
        "closestWordsFiltered(positive_words=['trees', 'grapes'], negative_words=['apples'], model=w2v_model)[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['swam', 'swim']"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#for swimming - walking + walked = ?\n",
        "closestWordsFiltered(positive_words=['swimming', 'walked'], negative_words=['walking'], model=w2v_model)[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['nurse', 'doctors']"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#for doctor - father + mother = ?\n",
        "closestWordsFiltered(positive_words=['doctor', 'mother'], negative_words=['father'], model=w2v_model)[:2]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And then for the GloVe model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['queen', 'princess']"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#for king - man + woman = ?\n",
        "closestWordsFiltered(positive_words=['king', 'woman'], negative_words=['man'], model=glove_model)[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['japan', 'japanese']"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#for France - Paris + Tokyo = ?\n",
        "#note we have to convert the words to lower in order to get results from the glove model\n",
        "closestWordsFiltered(positive_words=['france', 'tokyo'], negative_words=['paris'], model=glove_model)[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['vines', 'tree']"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#for trees - apples + grapes = ?\n",
        "closestWordsFiltered(positive_words=['trees', 'grapes'], negative_words=['apples'], model=glove_model)[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['swam', 'swimmers']"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#for swimming - walking + walked = ?\n",
        "closestWordsFiltered(positive_words=['swimming', 'walked'], negative_words=['walking'], model=glove_model)[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['nurse', 'doctors']"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#for doctor - father + mother = ?\n",
        "closestWordsFiltered(positive_words=['doctor', 'mother'], negative_words=['father'], model=glove_model)[:2]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Question 5\n",
        "In this part I'm going to try 3 different combinations of my own choice based on the above examples. These are:\n",
        "1. husband - man + woman\n",
        "2. bite - food + water\n",
        "3. groom - man + woman\n",
        "\n",
        "Starting with the word2vec model the results are as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['mother', 'wife']"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#for husband - man + woman = ?\n",
        "closestWordsFiltered(positive_words=['husband', 'woman'], negative_words=['man'], model=w2v_model)[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['backwashed', 'bugs_wiggling']"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#for eat - food + water = ?\n",
        "closestWordsFiltered(positive_words=['eat', 'water'], negative_words=['food'], model=w2v_model)[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['bride', 'Mohammad_Rassool_cousin']"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#for groom - man + woman = ?\n",
        "closestWordsFiltered(positive_words=['groom', 'woman'], negative_words=['man'], model=w2v_model)[:2]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And for the GloVe model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['wife', 'mother']"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#for husband - man + woman = ?\n",
        "closestWordsFiltered(positive_words=['husband', 'woman'], negative_words=['man'], model=glove_model)[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['drink', 'suck']"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#for eat - food + water = ?\n",
        "closestWordsFiltered(positive_words=['eat', 'water'], negative_words=['food'], model=glove_model)[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['bride', 'wedding']"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#for groom - man + woman = ?\n",
        "closestWordsFiltered(positive_words=['groom', 'woman'], negative_words=['man'], model=glove_model)[:2]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the results we can see that both the word2vec and the GloVe models are able to capture the relationships of different words based on their context. Putting this into perspective it seems that the numeric values of different vectors in the models share some common characteristics if, for example the word refers to a man. So, if we replace the numeric values that correspond to a man with those that refer to a woman, we'll get the relative vector for this word. For example, if we subtract the vector of man for the word 'king' and then add the vector for the word 'woman', the closest vector will be the one for the word 'queen'.\n",
        "\n",
        "Of course, this is not always the case depending on the words we provide to the model. For example, we can see that the word2vec model returned the vectors 'backwashed' and 'bugs_wiggling' as a result of the calculation 'eat - food + water' while we would probably expect the vector for the word 'drink' which was the output of the GloVe model."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
