{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise B: Traditional Text Classification\n",
    "#### Tzanis Nikolaos mtn2217"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we import all the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from time import time\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use pandas to read the train and test CSVs and convert them into DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Stocks End Up, But Near Year Lows (Reuters)</td>\n",
       "      <td>Reuters - Stocks ended slightly higher on Frid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>Money Funds Fell in Latest Week (AP)</td>\n",
       "      <td>AP - Assets of the nation's retail money marke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>Fed minutes show dissent over inflation (USATO...</td>\n",
       "      <td>USATODAY.com - Retail sales bounced back a bit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>Safety Net (Forbes.com)</td>\n",
       "      <td>Forbes.com - After earning a PH.D. in Sociolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black</td>\n",
       "      <td>NEW YORK (Reuters) - Short-sellers, Wall Stre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Index                                              Title  \\\n",
       "0            3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1            3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2            3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3            3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4            3  Oil prices soar to all-time record, posing new...   \n",
       "5            3        Stocks End Up, But Near Year Lows (Reuters)   \n",
       "6            3               Money Funds Fell in Latest Week (AP)   \n",
       "7            3  Fed minutes show dissent over inflation (USATO...   \n",
       "8            3                            Safety Net (Forbes.com)   \n",
       "9            3            Wall St. Bears Claw Back Into the Black   \n",
       "\n",
       "                                         Description  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
       "3  Reuters - Authorities have halted oil export\\f...  \n",
       "4  AFP - Tearaway world oil prices, toppling reco...  \n",
       "5  Reuters - Stocks ended slightly higher on Frid...  \n",
       "6  AP - Assets of the nation's retail money marke...  \n",
       "7  USATODAY.com - Retail sales bounced back a bit...  \n",
       "8  Forbes.com - After earning a PH.D. in Sociolog...  \n",
       "9   NEW YORK (Reuters) - Short-sellers, Wall Stre...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_raw = pd.read_csv('../data/train.csv')\n",
    "test_df_raw = pd.read_csv('../data/test.csv')\n",
    "train_df_raw.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to merge titles and descriptions and convert everything to lowercase. For that purpose we create a function that is going to be called for both the training and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeTitlesAndDescriptionsAndConvertToLowercase(dataframe):\n",
    "    new_dataframe = pd.DataFrame({'Class Index': dataframe['Class Index'], 'Text': dataframe['Title'].str.lower() + ' ' + dataframe['Description'].str.lower()})\n",
    "    return new_dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function is called for the training set first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = mergeTitlesAndDescriptionsAndConvertToLowercase(train_df_raw)\n",
    "\n",
    "X = train_df['Text'].copy()\n",
    "y = train_df['Class Index'].copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = mergeTitlesAndDescriptionsAndConvertToLowercase(test_df_raw)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we train the models and record the training time for each one of them. For that purpose we create a function that is goint to be called for all models. This function returns the predictions of each model and the results for Accuracy, Dimensionality and Time Cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(analyzer, ngram_range, model):\n",
    "    params = {\n",
    "    \"analyzer\": analyzer,\n",
    "    \"stop_words\": 'english',\n",
    "    \"ngram_range\": ngram_range\n",
    "    }\n",
    "\n",
    "    start = time()\n",
    "    vectorizer = TfidfVectorizer(**params)\n",
    "\n",
    "    X_train = vectorizer.fit_transform(train_df['Text'])\n",
    "    X_test = vectorizer.transform(test_df['Text'])\n",
    "\n",
    "    clf = model\n",
    "    clf.fit(X_train, y)\n",
    "    end = time()\n",
    "\n",
    "    time_needed = np.round(end-start, 2)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = np.round(accuracy_score(test_df['Class Index'], y_pred), 2)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Time needed:\", time_needed)\n",
    "    print(\"Dimensionality:\", len(vectorizer.vocabulary_))\n",
    "    return y_pred, [accuracy, len(vectorizer.vocabulary_), time_needed] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The array 'results' is created to store the results of each model in regards to Accuracy, Dimensionality and Time Cost, in order to create the Dataframe that will display the results later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we call the function for each of the models, starting with Multinomial Naive Bayes with word unigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n",
      "Time needed: 3.96\n",
      "Dimensionality: 64695\n"
     ]
    }
   ],
   "source": [
    "nb_word_unigrams_preds, result = trainModel('word', (1,1), MultinomialNB())\n",
    "results.append(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then for the Multinomial Naive Bayes with character trigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87\n",
      "Time needed: 18.02\n",
      "Dimensionality: 31074\n"
     ]
    }
   ],
   "source": [
    "nb_char_trigrams_preds, result = trainModel('char', (3,3), MultinomialNB())\n",
    "results.append(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then for the SVM Linear kernel with C=1 and word unigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92\n",
      "Time needed: 7.32\n",
      "Dimensionality: 64695\n"
     ]
    }
   ],
   "source": [
    "svm_word_unigrams_preds, result = trainModel('word', (1,1), LinearSVC(C=1))\n",
    "results.append(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then for the SVM Linear kernel with C=1 and character trigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91\n",
      "Time needed: 27.6\n",
      "Dimensionality: 31074\n"
     ]
    }
   ],
   "source": [
    "svm_char_trigrams_preds, result = trainModel('char', (3,3), LinearSVC(C=1))\n",
    "results.append(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, using the results array created earlier we create a pandas DataFrame to display the results in the matrix form requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NB (word 1-grams)</th>\n",
       "      <th>NB (char 3-grams)</th>\n",
       "      <th>SVM (word 1-grams)</th>\n",
       "      <th>SVM (char 3-grams)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dimensionality</th>\n",
       "      <td>64695.00</td>\n",
       "      <td>31074.00</td>\n",
       "      <td>64695.00</td>\n",
       "      <td>31074.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time Cost</th>\n",
       "      <td>3.96</td>\n",
       "      <td>18.02</td>\n",
       "      <td>7.32</td>\n",
       "      <td>27.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                NB (word 1-grams)  NB (char 3-grams)  SVM (word 1-grams)  \\\n",
       "Accuracy                     0.90               0.87                0.92   \n",
       "Dimensionality           64695.00           31074.00            64695.00   \n",
       "Time Cost                    3.96              18.02                7.32   \n",
       "\n",
       "                SVM (char 3-grams)  \n",
       "Accuracy                      0.91  \n",
       "Dimensionality            31074.00  \n",
       "Time Cost                    27.60  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results, columns=['Accuracy', 'Dimensionality', 'Time Cost'])\n",
    "results_df = results_df.rename(index={0: 'NB (word 1-grams)', 1: 'NB (char 3-grams)', 2: 'SVM (word 1-grams)', 3: 'SVM (char 3-grams)'})\n",
    "display(results_df.T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration of Misclassified Texts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are going to explore various texts that were misclassified from the various models and delve deeper trying to identify texts that were misclassified by all the models. After that, we print a random text that was classified incorrectly by all the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example text was was misclassified by all the models was:\n",
      "bbc 'must keep up' bbc boss mark thompson says the corporation must keep up with change, after announcing nearly 3,000 job cuts.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "misclassified_texts = []\n",
    "for i in range(len(test_df)):\n",
    "    if ((nb_word_unigrams_preds[i] != test_df['Class Index'][i]) and (nb_char_trigrams_preds[i] != test_df['Class Index'][i]) and (svm_word_unigrams_preds[i] != test_df['Class Index'][i]) and (svm_char_trigrams_preds[i] != test_df['Class Index'][i])):\n",
    "        misclassified_texts.append(i)\n",
    "\n",
    "if len(misclassified_texts) != 0:\n",
    "    print('An example text was was misclassified by all the models was:')\n",
    "    print(test_df.iloc[random.choice(misclassified_texts)]['Text'])\n",
    "else:\n",
    "    print('All texts were classified correctly by at least one model.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then using the test dataframe we explore how many texts were classified incorrectly per category. Actually, by using the index of the misclassified texts we count how many times this particular index was misclassified in the test dataframe. There is also a line of code that converts numeric indexes to strings for better visibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of texts that were misclassified by all models per category:\n",
      "World       112\n",
      "Sports        9\n",
      "Business    138\n",
      "Sci/Tech     88\n",
      "Name: Class Index, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "misclassified_per_category = test_df.iloc[misclassified_texts]['Class Index'].value_counts().sort_index()\n",
    "misclassified_per_category.index = misclassified_per_category.index.map({1: 'World', 2: 'Sports', 3: 'Business', 4: 'Sci/Tech'})\n",
    "print('Number of texts that were misclassified by all models per category:')\n",
    "print(misclassified_per_category)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last part of the exercise a dictionary to save the misclassification counts is initialized. Then we go through all the misclassified texts, creating tuples where the first number represents the correct category and the second number represents the wrong prediction of the models. Using the Counter library we get the total counts of each tuple and then print the one that has the highest count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common pair of correct category and wrong prediction was ('Business', 'Sci/Tech'). It was encountered a total of 395 times.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "misclassification_counts = {}\n",
    "\n",
    "for i in misclassified_texts:\n",
    "    true_label = test_df.iloc[i]['Class Index']\n",
    "    \n",
    "    predicted_labels = [nb_word_unigrams_preds[i], nb_char_trigrams_preds[i], svm_word_unigrams_preds[i], svm_char_trigrams_preds[i]]    \n",
    "    predicted_label_counts = Counter(predicted_labels)\n",
    "    \n",
    "    del predicted_label_counts[true_label]\n",
    "    \n",
    "    for predicted_label, count in predicted_label_counts.items():\n",
    "        pair = (true_label, predicted_label)\n",
    "        misclassification_counts[pair] = misclassification_counts.get(pair, 0) + count\n",
    "\n",
    "most_frequent_pair, count = max(misclassification_counts.items(), key=lambda x: x[1])\n",
    "\n",
    "map_dict = {1: 'World', 2: 'Sports', 3: 'Business', 4: 'Sci/Tech'}\n",
    "\n",
    "print(f'The most common pair of correct category and wrong prediction was {tuple(map_dict[num] for num in most_frequent_pair)}. It was encountered a total of {count} times.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
