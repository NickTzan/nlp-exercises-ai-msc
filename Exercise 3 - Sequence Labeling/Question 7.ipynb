{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#\n# Named-entity recognition using BERT\n# Dataset: https://www.kaggle.com/datasets/alaakhaled/conll003-englishversion\n#\n\n# dependencies\nimport torch\nimport torch.optim as optim \nfrom torchtext.vocab import build_vocab_from_iterator\nfrom transformers import BertForTokenClassification, BertTokenizerFast\nfrom sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report\nimport tqdm\ntqdmn = tqdm.notebook.tqdm","metadata":{"execution":{"iopub.status.busy":"2023-06-03T20:11:59.953579Z","iopub.execute_input":"2023-06-03T20:11:59.953995Z","iopub.status.idle":"2023-06-03T20:11:59.960206Z","shell.execute_reply.started":"2023-06-03T20:11:59.953968Z","shell.execute_reply":"2023-06-03T20:11:59.959087Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"# hyper-parameters\nEPOCHS = 3\nBATCH_SIZE = 8\nLR = 1e-5","metadata":{"execution":{"iopub.status.busy":"2023-06-03T20:12:00.045043Z","iopub.execute_input":"2023-06-03T20:12:00.045329Z","iopub.status.idle":"2023-06-03T20:12:00.050167Z","shell.execute_reply.started":"2023-06-03T20:12:00.045304Z","shell.execute_reply":"2023-06-03T20:12:00.049227Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"# the path of the data files\nbase_path = '/kaggle/input/conll003-englishversion/'\n\n# use GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-06-03T20:12:00.052062Z","iopub.execute_input":"2023-06-03T20:12:00.052724Z","iopub.status.idle":"2023-06-03T20:12:00.061674Z","shell.execute_reply.started":"2023-06-03T20:12:00.052681Z","shell.execute_reply":"2023-06-03T20:12:00.060659Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"# read the data files\ndef load_sentences(filepath):\n\n    sentences = []\n    tokens = []\n    pos_tags = []\n    chunk_tags = []\n    ner_tags = []\n\n    with open(filepath, 'r') as f:\n        \n        for line in f.readlines():\n            \n            if (line == ('-DOCSTART- -X- -X- O\\n') or line == '\\n'):\n                if len(tokens) > 0:\n                    sentences.append({'tokens': tokens, 'pos_tags': pos_tags, 'chunk_tags': chunk_tags, 'ner_tags': ner_tags})\n                    tokens = []\n                    pos_tags = []\n                    chunk_tags = []\n                    ner_tags = []\n            else:\n                l = line.split(' ')\n                tokens.append(l[0])\n                pos_tags.append(l[1])\n                chunk_tags.append(l[2])\n                ner_tags.append(l[3].strip('\\n'))\n    \n    return sentences","metadata":{"execution":{"iopub.status.busy":"2023-06-03T20:12:00.125986Z","iopub.execute_input":"2023-06-03T20:12:00.126502Z","iopub.status.idle":"2023-06-03T20:12:00.136628Z","shell.execute_reply.started":"2023-06-03T20:12:00.126470Z","shell.execute_reply":"2023-06-03T20:12:00.135772Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"print('loading data')\ntrain_sentences = load_sentences(base_path + 'train.txt')\ntest_sentences = load_sentences(base_path + 'test.txt')\nvalid_sentences = load_sentences(base_path + 'valid.txt')","metadata":{"execution":{"iopub.status.busy":"2023-06-03T20:12:00.138496Z","iopub.execute_input":"2023-06-03T20:12:00.139365Z","iopub.status.idle":"2023-06-03T20:12:01.113833Z","shell.execute_reply.started":"2023-06-03T20:12:00.139331Z","shell.execute_reply":"2023-06-03T20:12:01.112868Z"},"trusted":true},"execution_count":112,"outputs":[{"name":"stdout","text":"loading data\n","output_type":"stream"}]},{"cell_type":"markdown","source":"When specifying the tags that are going to be used we replace the 'ner_tags' with 'chunk_tags' in this block of code.","metadata":{}},{"cell_type":"code","source":"# build tagset and tag ids\ntags = [sentence['chunk_tags'] for sentence in train_sentences]\ntagmap = build_vocab_from_iterator(tags)\ntagset = set([item for sublist in tags for item in sublist])\nprint('Tagset size:',len(tagset))","metadata":{"execution":{"iopub.status.busy":"2023-06-03T20:12:01.116236Z","iopub.execute_input":"2023-06-03T20:12:01.116932Z","iopub.status.idle":"2023-06-03T20:12:01.223820Z","shell.execute_reply.started":"2023-06-03T20:12:01.116899Z","shell.execute_reply":"2023-06-03T20:12:01.222889Z"},"trusted":true},"execution_count":113,"outputs":[{"name":"stdout","text":"Tagset size: 20\n","output_type":"stream"}]},{"cell_type":"code","source":"# load BERT tokenizer\nbert_version = 'bert-base-uncased'\ntokenizer = BertTokenizerFast.from_pretrained(bert_version)","metadata":{"execution":{"iopub.status.busy":"2023-06-03T20:12:01.226294Z","iopub.execute_input":"2023-06-03T20:12:01.226876Z","iopub.status.idle":"2023-06-03T20:12:01.386060Z","shell.execute_reply.started":"2023-06-03T20:12:01.226843Z","shell.execute_reply":"2023-06-03T20:12:01.384953Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"# map tokens and tags to token ids and label ids\ndef align_label(tokens, labels):\n\n    word_ids = tokens.word_ids()\n    previous_word_idx = None\n    label_ids = []\n    for word_idx in word_ids:\n        if word_idx is None:\n            label_ids.append(-100)\n        elif word_idx != previous_word_idx:\n            try:\n                label_ids.append(tagmap[labels[word_idx]])\n            except:\n                label_ids.append(-100)\n        else:\n                label_ids.append(-100)\n        previous_word_idx = word_idx\n\n    return label_ids","metadata":{"execution":{"iopub.status.busy":"2023-06-03T20:12:01.389893Z","iopub.execute_input":"2023-06-03T20:12:01.390206Z","iopub.status.idle":"2023-06-03T20:12:01.400808Z","shell.execute_reply.started":"2023-06-03T20:12:01.390181Z","shell.execute_reply":"2023-06-03T20:12:01.399704Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"markdown","source":"In the next block the ner_tags should also be replaced with chunk_tags.","metadata":{}},{"cell_type":"code","source":"def encode(sentence):\n    encodings = tokenizer(sentence['tokens'], truncation=True, padding='max_length', is_split_into_words=True)\n    labels = align_label(encodings, sentence['chunk_tags'])\n    return { 'input_ids': torch.LongTensor(encodings.input_ids), 'attention_mask': torch.LongTensor(encodings.attention_mask), 'labels': torch.LongTensor(labels) }","metadata":{"execution":{"iopub.status.busy":"2023-06-03T20:12:01.402569Z","iopub.execute_input":"2023-06-03T20:12:01.402990Z","iopub.status.idle":"2023-06-03T20:12:01.410945Z","shell.execute_reply.started":"2023-06-03T20:12:01.402936Z","shell.execute_reply":"2023-06-03T20:12:01.410108Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"print('encoding data')\ntrain_dataset = [encode(sentence) for sentence in train_sentences]\nvalid_dataset = [encode(sentence) for sentence in valid_sentences]\ntest_dataset = [encode(sentence) for sentence in test_sentences]","metadata":{"execution":{"iopub.status.busy":"2023-06-03T20:12:01.412398Z","iopub.execute_input":"2023-06-03T20:12:01.412849Z","iopub.status.idle":"2023-06-03T20:12:16.776693Z","shell.execute_reply.started":"2023-06-03T20:12:01.412817Z","shell.execute_reply":"2023-06-03T20:12:16.775753Z"},"trusted":true},"execution_count":117,"outputs":[{"name":"stdout","text":"encoding data\n","output_type":"stream"}]},{"cell_type":"code","source":"# initialize the model including a classification layer with num_labels classes\nprint('initializing the model')\nmodel = BertForTokenClassification.from_pretrained(bert_version, num_labels=len(tagset))\nmodel.to(device)\noptimizer = optim.AdamW(params=model.parameters(), lr=LR)","metadata":{"execution":{"iopub.status.busy":"2023-06-03T20:12:16.778388Z","iopub.execute_input":"2023-06-03T20:12:16.778775Z","iopub.status.idle":"2023-06-03T20:12:17.911511Z","shell.execute_reply.started":"2023-06-03T20:12:16.778740Z","shell.execute_reply":"2023-06-03T20:12:17.910560Z"},"trusted":true},"execution_count":118,"outputs":[{"name":"stdout","text":"initializing the model\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# prepare batches of data\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-06-03T20:12:17.913654Z","iopub.execute_input":"2023-06-03T20:12:17.914052Z","iopub.status.idle":"2023-06-03T20:12:17.987633Z","shell.execute_reply.started":"2023-06-03T20:12:17.914017Z","shell.execute_reply":"2023-06-03T20:12:17.986735Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"# evaluate the performance of the model\ndef EvaluateModel(model, data_loader, question_2 = False):\n    model.eval()\n    with torch.no_grad():\n        Y_actual, Y_preds = [],[]\n        for i, batch in enumerate(tqdmn(data_loader)):\n            # move the batch tensors to the same device as the model\n            batch = { k: v.to(device) for k, v in batch.items() }\n            # send 'input_ids', 'attention_mask' and 'labels' to the model\n            outputs = model(**batch)\n            # iterate through the examples\n            for idx, _ in enumerate(batch['labels']):\n                # get the true values\n                true_values_all = batch['labels'][idx]\n                true_values = true_values_all[true_values_all != -100]\n                # get the predicted values\n                pred_values = torch.argmax(outputs[1], dim=2)[idx]\n                pred_values = pred_values[true_values_all != -100]\n                # update the lists of true answers and predictions\n                Y_actual.append(true_values)\n                Y_preds.append(pred_values)\n    if question_2 == False:\n        Y_actual = torch.cat(Y_actual)\n        Y_preds = torch.cat(Y_preds)\n        # Return list of actual labels, predicted labels \n        return Y_actual.detach().cpu().numpy(), Y_preds.detach().cpu().numpy()\n    else:\n        # Return actual and predicted labels per sentence\n        return [y.detach().cpu().numpy() for y in Y_actual], [y.detach().cpu().numpy() for y in Y_preds]","metadata":{"execution":{"iopub.status.busy":"2023-06-03T20:12:17.994326Z","iopub.execute_input":"2023-06-03T20:12:17.994624Z","iopub.status.idle":"2023-06-03T20:12:18.006304Z","shell.execute_reply.started":"2023-06-03T20:12:17.994589Z","shell.execute_reply":"2023-06-03T20:12:18.005144Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"# train the model\nprint('training the model')\nfor epoch in tqdmn(range(EPOCHS)):\n    model.train()\n    print('epoch',epoch+1)\n    # iterate through each batch of the train data\n    for i, batch in enumerate(tqdmn(train_loader)):\n        # move the batch tensors to the same device as the model\n        batch = { k: v.to(device) for k, v in batch.items() }\n        # send 'input_ids', 'attention_mask' and 'labels' to the model\n        outputs = model(**batch)\n        loss = outputs[0]\n        # set the gradients to zero\n        optimizer.zero_grad()\n        # propagate the loss backwards\n        loss.backward()\n        # update the model weights\n        optimizer.step()\n    # calculate performence on validation set\n    Y_actual, Y_preds = EvaluateModel(model,valid_loader)\n    print(\"\\nValidation Accuracy : {:.3f}\".format(accuracy_score(Y_actual, Y_preds)))\n    print(\"\\nValidation Macro-Accuracy : {:.3f}\".format(balanced_accuracy_score(Y_actual, Y_preds)))","metadata":{"execution":{"iopub.status.busy":"2023-06-03T20:12:18.007928Z","iopub.execute_input":"2023-06-03T20:12:18.008271Z","iopub.status.idle":"2023-06-03T20:52:21.825312Z","shell.execute_reply.started":"2023-06-03T20:12:18.008240Z","shell.execute_reply":"2023-06-03T20:52:21.824143Z"},"trusted":true},"execution_count":121,"outputs":[{"name":"stdout","text":"training the model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f14b31003f3d424292820669c1d566b0"}},"metadata":{}},{"name":"stdout","text":"epoch 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1756 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f465f89da3b4b8289e6403ad6c72577"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/407 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd3d9174e8e745319e66feba60aa601c"}},"metadata":{}},{"name":"stdout","text":"\nValidation Accuracy : 0.949\n\nValidation Macro-Accuracy : 0.504\nepoch 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1756 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd667ceeeda347d4a6e9cd1c32e12a7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/407 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b08d5613d4c84d2982e91ee05aac2daf"}},"metadata":{}},{"name":"stdout","text":"\nValidation Accuracy : 0.954\n\nValidation Macro-Accuracy : 0.585\nepoch 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1756 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"621a9e0b215e404aaf401ac8d4c628d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/407 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11000de7756340d885f8c448bf562cd5"}},"metadata":{}},{"name":"stdout","text":"\nValidation Accuracy : 0.956\n\nValidation Macro-Accuracy : 0.626\n","output_type":"stream"}]},{"cell_type":"code","source":"print('applying the model to the test set')\n# apply the trained model to the test set\nY_actual, Y_preds = EvaluateModel(model,test_loader)","metadata":{"execution":{"iopub.status.busy":"2023-06-03T20:52:21.826976Z","iopub.execute_input":"2023-06-03T20:52:21.827444Z","iopub.status.idle":"2023-06-03T20:53:20.840098Z","shell.execute_reply.started":"2023-06-03T20:52:21.827409Z","shell.execute_reply":"2023-06-03T20:53:20.839175Z"},"trusted":true},"execution_count":122,"outputs":[{"name":"stdout","text":"applying the model to the test set\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/432 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aefce22eef56487c923bfb9044bf3a83"}},"metadata":{}}]},{"cell_type":"code","source":"print(\"\\nTest Accuracy : {:.3f}\".format(accuracy_score(Y_actual, Y_preds)))\nprint(\"\\nTest Macro-Accuracy : {:.3f}\".format(balanced_accuracy_score(Y_actual, Y_preds)))\nprint(\"\\nClassification Report : \")\nprint(classification_report(Y_actual, Y_preds,labels = tagmap(tagmap.get_itos()), target_names = tagmap.get_itos(), zero_division = 0))","metadata":{"execution":{"iopub.status.busy":"2023-06-03T20:53:20.844147Z","iopub.execute_input":"2023-06-03T20:53:20.846182Z","iopub.status.idle":"2023-06-03T20:53:20.969923Z","shell.execute_reply.started":"2023-06-03T20:53:20.846149Z","shell.execute_reply":"2023-06-03T20:53:20.969008Z"},"trusted":true},"execution_count":123,"outputs":[{"name":"stdout","text":"\nTest Accuracy : 0.951\n\nTest Macro-Accuracy : 0.611\n\nClassification Report : \n              precision    recall  f1-score   support\n\n        I-NP       0.96      0.96      0.96     16177\n        B-NP       0.95      0.95      0.95     12985\n           O       0.98      0.98      0.98      6210\n        B-PP       0.96      0.99      0.97      3979\n        B-VP       0.94      0.92      0.93      3767\n        I-VP       0.91      0.94      0.93      1913\n      B-ADVP       0.80      0.73      0.76       559\n      B-SBAR       0.88      0.83      0.86       296\n      B-ADJP       0.72      0.63      0.67       276\n       B-PRT       0.67      0.77      0.72       110\n      I-ADJP       0.56      0.67      0.61        55\n      I-ADVP       0.56      0.30      0.39        33\n        I-PP       0.88      0.47      0.61        15\n      B-INTJ       0.00      0.00      0.00        13\n     I-CONJP       0.29      0.29      0.29         7\n       B-LST       1.00      0.21      0.34        29\n     B-CONJP       0.50      0.17      0.25         6\n      I-SBAR       1.00      0.20      0.33         5\n       I-LST       0.00      0.00      0.00         0\n      I-INTJ       0.00      0.00      0.00         0\n\n   micro avg       0.95      0.95      0.95     46435\n   macro avg       0.68      0.55      0.58     46435\nweighted avg       0.95      0.95      0.95     46435\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\ndef find_sentence_with_at_least_one_wrong_label(Y_actual, Y_preds):\n    for i, (preds, labels) in enumerate(zip(Y_preds, Y_actual)):\n        num_of_wrong_labels = sum(np.array(preds) != np.array(labels))\n        if len(labels) >= 10 and num_of_wrong_labels > 0:\n            tokens = test_sentences[i][\"tokens\"]\n            preds = preds[labels != -100]\n            predictions = [tagmap.get_itos()[p] for p in preds]\n            labels = labels[labels != -100]\n            labels = [tagmap.get_itos()[l] for l in labels]\n            break\n    return tokens, predictions, labels\n\nY_actual, Y_preds = EvaluateModel(model, test_loader, question_2 = True)\ntokens, predictions, labels = find_sentence_with_at_least_one_wrong_label(Y_actual, Y_preds)\n\nprint('\\nThe actual and predicted tags for the tokens of this sentence were:')\nprint(\"\\n{:<10} {:<10} {:<10}\".format('Token', 'Actual Tag', 'Predicted Tag'))\n\nfor i in range(len(tokens)):\n    print(\"{:<10} {:<10} {:<10}\".format(tokens[i], labels[i], predictions[i]))","metadata":{"execution":{"iopub.status.busy":"2023-06-03T20:53:20.974062Z","iopub.execute_input":"2023-06-03T20:53:20.976193Z","iopub.status.idle":"2023-06-03T20:54:20.163181Z","shell.execute_reply.started":"2023-06-03T20:53:20.976162Z","shell.execute_reply":"2023-06-03T20:54:20.162097Z"},"trusted":true},"execution_count":124,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/432 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8f444cf31bd4c578483efd41df15cd0"}},"metadata":{}},{"name":"stdout","text":"\nThe actual and predicted tags for the tokens of this sentence were:\n\nToken      Actual Tag Predicted Tag\nSOCCER     B-NP       B-NP      \n-          O          O         \nJAPAN      B-NP       B-NP      \nGET        B-VP       I-NP      \nLUCKY      B-NP       I-NP      \nWIN        I-NP       I-NP      \n,          O          O         \nCHINA      B-NP       B-NP      \nIN         B-PP       B-PP      \nSURPRISE   B-NP       B-NP      \nDEFEAT     I-NP       I-NP      \n.          O          O         \n","output_type":"stream"}]},{"cell_type":"code","source":"test_sentence_dict = {'tokens': ['Zurich', 'and', 'some', 'other', 'insurers', 'with', 'big', 'fleets', 'of', 'engineers', 'are', 'advising', 'companies', 'on', 'how', 'to', 'fortify', 'their', 'properties', '.'],\n                      'pos_tags': ['NNP', 'CC', 'DT', 'JJ', 'NNS', 'IN', 'JJ', 'NNS', 'IN', 'NNS', 'VBP', 'VBG', 'NNS', 'IN', 'WRB', 'TO', 'VB', 'PRP$', 'NNS', '.'],\n                      'chunk_tags': ['B-NP', 'O', 'B-NP', 'I-NP', 'B-NP', 'B-PP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'B-VP', 'B-VP', 'B-NP', 'B-PP', 'B-ADVP', 'B-VP', 'B-VP', 'B-NP', 'I-NP', 'O'],\n                      'ner_tags': ['B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}\n\nnew_test_dataset = [encode(test_sentence_dict)]\nnew_test_loader = torch.utils.data.DataLoader(new_test_dataset, batch_size=1)\nnew_Y_actual, new_Y_preds = EvaluateModel(model,new_test_loader )\n\nprint('\\nThe actual and predicted tags for the tokens of this sentence were:')\nprint(\"\\n{:<10} {:<10} {:<10}\".format('Token', 'Actual Tag', 'Predicted Tag'))\n\nfor i in range(len(test_sentence_dict['tokens'])):\n    token = test_sentence_dict['tokens'][i]\n    print(\"{:<10} {:<10} {:<10}\".format(token, tagmap.get_itos()[new_Y_actual[i].item()], tagmap.get_itos()[new_Y_preds[i].item()]))","metadata":{"execution":{"iopub.status.busy":"2023-06-03T20:54:20.164594Z","iopub.execute_input":"2023-06-03T20:54:20.165371Z","iopub.status.idle":"2023-06-03T20:54:20.221686Z","shell.execute_reply.started":"2023-06-03T20:54:20.165339Z","shell.execute_reply":"2023-06-03T20:54:20.220542Z"},"trusted":true},"execution_count":125,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fac9da51993b4579819a2b5f77491eb0"}},"metadata":{}},{"name":"stdout","text":"\nThe actual and predicted tags for the tokens of this sentence were:\n\nToken      Actual Tag Predicted Tag\nZurich     B-NP       B-NP      \nand        O          O         \nsome       B-NP       B-NP      \nother      I-NP       I-NP      \ninsurers   B-NP       I-NP      \nwith       B-PP       B-PP      \nbig        B-NP       B-NP      \nfleets     I-NP       I-NP      \nof         B-PP       B-PP      \nengineers  B-NP       B-NP      \nare        B-VP       B-VP      \nadvising   B-VP       I-VP      \ncompanies  B-NP       B-NP      \non         B-PP       B-PP      \nhow        B-ADVP     B-ADVP    \nto         B-VP       B-VP      \nfortify    B-VP       I-VP      \ntheir      B-NP       B-NP      \nproperties I-NP       I-NP      \n.          O          O         \n","output_type":"stream"}]}]}