{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#\n# Named-entity recognition using BERT\n# Dataset: https://www.kaggle.com/datasets/alaakhaled/conll003-englishversion\n#\n\n# dependencies\nimport torch\nimport torch.optim as optim \nfrom torchtext.vocab import build_vocab_from_iterator\nfrom transformers import BertForTokenClassification, BertTokenizerFast\nfrom sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report\nimport tqdm\ntqdmn = tqdm.notebook.tqdm","metadata":{"execution":{"iopub.status.busy":"2023-06-02T15:42:07.430350Z","iopub.execute_input":"2023-06-02T15:42:07.430761Z","iopub.status.idle":"2023-06-02T15:42:07.436648Z","shell.execute_reply.started":"2023-06-02T15:42:07.430733Z","shell.execute_reply":"2023-06-02T15:42:07.435612Z"},"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"code","source":"# hyper-parameters\nEPOCHS = 3\nBATCH_SIZE = 8\nLR = 1e-5","metadata":{"execution":{"iopub.status.busy":"2023-06-02T15:42:07.443137Z","iopub.execute_input":"2023-06-02T15:42:07.444375Z","iopub.status.idle":"2023-06-02T15:42:07.449063Z","shell.execute_reply.started":"2023-06-02T15:42:07.444341Z","shell.execute_reply":"2023-06-02T15:42:07.448203Z"},"trusted":true},"execution_count":155,"outputs":[]},{"cell_type":"code","source":"# the path of the data files\nbase_path = '/kaggle/input/conll003-englishversion/'\n\n# use GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-06-02T15:42:07.450967Z","iopub.execute_input":"2023-06-02T15:42:07.451750Z","iopub.status.idle":"2023-06-02T15:42:07.459334Z","shell.execute_reply.started":"2023-06-02T15:42:07.451714Z","shell.execute_reply":"2023-06-02T15:42:07.458267Z"},"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"code","source":"# read the data files\ndef load_sentences(filepath):\n\n    sentences = []\n    tokens = []\n    pos_tags = []\n    chunk_tags = []\n    ner_tags = []\n\n    with open(filepath, 'r') as f:\n        \n        for line in f.readlines():\n            \n            if (line == ('-DOCSTART- -X- -X- O\\n') or line == '\\n'):\n                if len(tokens) > 0:\n                    sentences.append({'tokens': tokens, 'pos_tags': pos_tags, 'chunk_tags': chunk_tags, 'ner_tags': ner_tags})\n                    tokens = []\n                    pos_tags = []\n                    chunk_tags = []\n                    ner_tags = []\n            else:\n                l = line.split(' ')\n                tokens.append(l[0])\n                pos_tags.append(l[1])\n                chunk_tags.append(l[2])\n                ner_tags.append(l[3].strip('\\n'))\n    \n    return sentences","metadata":{"execution":{"iopub.status.busy":"2023-06-02T15:42:07.464756Z","iopub.execute_input":"2023-06-02T15:42:07.465716Z","iopub.status.idle":"2023-06-02T15:42:07.475035Z","shell.execute_reply.started":"2023-06-02T15:42:07.465684Z","shell.execute_reply":"2023-06-02T15:42:07.474023Z"},"trusted":true},"execution_count":157,"outputs":[]},{"cell_type":"markdown","source":"First, we change this block of code by adding the train and validation sentences.","metadata":{}},{"cell_type":"code","source":"print('loading data')\ntrain_sentences = load_sentences(base_path + 'train.txt') + load_sentences(base_path + 'valid.txt')\ntest_sentences = load_sentences(base_path + 'test.txt')","metadata":{"execution":{"iopub.status.busy":"2023-06-02T15:42:07.477104Z","iopub.execute_input":"2023-06-02T15:42:07.478102Z","iopub.status.idle":"2023-06-02T15:42:07.943731Z","shell.execute_reply.started":"2023-06-02T15:42:07.478034Z","shell.execute_reply":"2023-06-02T15:42:07.942701Z"},"trusted":true},"execution_count":158,"outputs":[{"name":"stdout","text":"loading data\n","output_type":"stream"}]},{"cell_type":"code","source":"# build tagset and tag ids\ntags = [sentence['ner_tags'] for sentence in train_sentences]\ntagmap = build_vocab_from_iterator(tags)\ntagset = set([item for sublist in tags for item in sublist])\nprint('Tagset size:',len(tagset))","metadata":{"execution":{"iopub.status.busy":"2023-06-02T15:42:07.945778Z","iopub.execute_input":"2023-06-02T15:42:07.946237Z","iopub.status.idle":"2023-06-02T15:42:08.116727Z","shell.execute_reply.started":"2023-06-02T15:42:07.946205Z","shell.execute_reply":"2023-06-02T15:42:08.115575Z"},"trusted":true},"execution_count":159,"outputs":[{"name":"stdout","text":"Tagset size: 9\n","output_type":"stream"}]},{"cell_type":"code","source":"# load BERT tokenizer\nbert_version = 'bert-base-uncased'\ntokenizer = BertTokenizerFast.from_pretrained(bert_version)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T15:42:08.118285Z","iopub.execute_input":"2023-06-02T15:42:08.118651Z","iopub.status.idle":"2023-06-02T15:42:08.416189Z","shell.execute_reply.started":"2023-06-02T15:42:08.118618Z","shell.execute_reply":"2023-06-02T15:42:08.414232Z"},"trusted":true},"execution_count":160,"outputs":[]},{"cell_type":"code","source":"# map tokens and tags to token ids and label ids\ndef align_label(tokens, labels):\n\n    word_ids = tokens.word_ids()\n    previous_word_idx = None\n    label_ids = []\n    for word_idx in word_ids:\n        if word_idx is None:\n            label_ids.append(-100)\n        elif word_idx != previous_word_idx:\n            try:\n                label_ids.append(tagmap[labels[word_idx]])\n            except:\n                label_ids.append(-100)\n        else:\n                label_ids.append(-100)\n        previous_word_idx = word_idx\n\n    return label_ids","metadata":{"execution":{"iopub.status.busy":"2023-06-02T15:42:08.421064Z","iopub.execute_input":"2023-06-02T15:42:08.421647Z","iopub.status.idle":"2023-06-02T15:42:08.431928Z","shell.execute_reply.started":"2023-06-02T15:42:08.421610Z","shell.execute_reply":"2023-06-02T15:42:08.428526Z"},"trusted":true},"execution_count":161,"outputs":[]},{"cell_type":"code","source":"def encode(sentence):\n    encodings = tokenizer(sentence['tokens'], truncation=True, padding='max_length', is_split_into_words=True)\n    labels = align_label(encodings, sentence['ner_tags'])\n    return { 'input_ids': torch.LongTensor(encodings.input_ids), 'attention_mask': torch.LongTensor(encodings.attention_mask), 'labels': torch.LongTensor(labels) }","metadata":{"execution":{"iopub.status.busy":"2023-06-02T15:42:08.434134Z","iopub.execute_input":"2023-06-02T15:42:08.434501Z","iopub.status.idle":"2023-06-02T15:42:08.447858Z","shell.execute_reply.started":"2023-06-02T15:42:08.434469Z","shell.execute_reply":"2023-06-02T15:42:08.446187Z"},"trusted":true},"execution_count":162,"outputs":[]},{"cell_type":"markdown","source":"In this block we no longer need the validation dataset.","metadata":{}},{"cell_type":"code","source":"print('encoding data')\ntrain_dataset = [encode(sentence) for sentence in train_sentences]\n# valid_dataset = [encode(sentence) for sentence in valid_sentences]\ntest_dataset = [encode(sentence) for sentence in test_sentences]","metadata":{"execution":{"iopub.status.busy":"2023-06-02T15:42:08.449489Z","iopub.execute_input":"2023-06-02T15:42:08.450053Z","iopub.status.idle":"2023-06-02T15:42:22.057590Z","shell.execute_reply.started":"2023-06-02T15:42:08.450019Z","shell.execute_reply":"2023-06-02T15:42:22.056624Z"},"trusted":true},"execution_count":163,"outputs":[{"name":"stdout","text":"encoding data\n","output_type":"stream"}]},{"cell_type":"code","source":"# initialize the model including a classification layer with num_labels classes\nprint('initializing the model')\nmodel = BertForTokenClassification.from_pretrained(bert_version, num_labels=len(tagset))\nmodel.to(device)\noptimizer = optim.AdamW(params=model.parameters(), lr=LR)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T15:42:22.059284Z","iopub.execute_input":"2023-06-02T15:42:22.059624Z","iopub.status.idle":"2023-06-02T15:42:23.262727Z","shell.execute_reply.started":"2023-06-02T15:42:22.059593Z","shell.execute_reply":"2023-06-02T15:42:23.261719Z"},"trusted":true},"execution_count":164,"outputs":[{"name":"stdout","text":"initializing the model\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"In this block the valid loader is also commented out.","metadata":{}},{"cell_type":"code","source":"# prepare batches of data\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n# valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T15:42:23.264127Z","iopub.execute_input":"2023-06-02T15:42:23.264559Z","iopub.status.idle":"2023-06-02T15:42:23.271253Z","shell.execute_reply.started":"2023-06-02T15:42:23.264526Z","shell.execute_reply":"2023-06-02T15:42:23.269279Z"},"trusted":true},"execution_count":165,"outputs":[]},{"cell_type":"code","source":"# evaluate the performance of the model\ndef EvaluateModel(model, data_loader):\n    model.eval()\n    with torch.no_grad():\n        Y_actual, Y_preds = [],[]\n        for i, batch in enumerate(tqdmn(data_loader)):\n            # move the batch tensors to the same device as the model\n            batch = { k: v.to(device) for k, v in batch.items() }\n            # send 'input_ids', 'attention_mask' and 'labels' to the model\n            outputs = model(**batch)\n            # iterate through the examples\n            for idx, _ in enumerate(batch['labels']):\n                # get the true values\n                true_values_all = batch['labels'][idx]\n                true_values = true_values_all[true_values_all != -100]\n                # get the predicted values\n                pred_values = torch.argmax(outputs[1], dim=2)[idx]\n                pred_values = pred_values[true_values_all != -100]\n                # update the lists of true answers and predictions\n                Y_actual.append(true_values)\n                Y_preds.append(pred_values)\n        Y_actual = torch.cat(Y_actual)\n        Y_preds = torch.cat(Y_preds)\n    # Return list of actual labels, predicted labels \n    return Y_actual.detach().cpu().numpy(), Y_preds.detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2023-06-02T15:42:23.272618Z","iopub.execute_input":"2023-06-02T15:42:23.273273Z","iopub.status.idle":"2023-06-02T15:42:23.283399Z","shell.execute_reply.started":"2023-06-02T15:42:23.273239Z","shell.execute_reply":"2023-06-02T15:42:23.282375Z"},"trusted":true},"execution_count":166,"outputs":[]},{"cell_type":"markdown","source":"The calculation of the performance is also commented out as we no longer have a validation set.","metadata":{}},{"cell_type":"code","source":"# train the model\nprint('training the model')\nfor epoch in tqdmn(range(EPOCHS)):\n    model.train()\n    print('epoch',epoch+1)\n    # iterate through each batch of the train data\n    for i, batch in enumerate(tqdmn(train_loader)):\n        # move the batch tensors to the same device as the model\n        batch = { k: v.to(device) for k, v in batch.items() }\n        # send 'input_ids', 'attention_mask' and 'labels' to the model\n        outputs = model(**batch)\n        loss = outputs[0]\n        # set the gradients to zero\n        optimizer.zero_grad()\n        # propagate the loss backwards\n        loss.backward()\n        # update the model weights\n        optimizer.step()\n    # calculate performence on validation set\n#     Y_actual, Y_preds = EvaluateModel(model,valid_loader)\n#     print(\"\\nValidation Accuracy : {:.3f}\".format(accuracy_score(Y_actual, Y_preds)))\n#     print(\"\\nValidation Macro-Accuracy : {:.3f}\".format(balanced_accuracy_score(Y_actual, Y_preds)))","metadata":{"execution":{"iopub.status.busy":"2023-06-02T15:42:23.287986Z","iopub.execute_input":"2023-06-02T15:42:23.288259Z","iopub.status.idle":"2023-06-02T16:28:20.074801Z","shell.execute_reply.started":"2023-06-02T15:42:23.288236Z","shell.execute_reply":"2023-06-02T16:28:20.073858Z"},"trusted":true},"execution_count":167,"outputs":[{"name":"stdout","text":"training the model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cfbaf58bdc943719da2b442a3bfd752"}},"metadata":{}},{"name":"stdout","text":"epoch 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2162 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51f4b61e753e4a28a68372d9161dc72b"}},"metadata":{}},{"name":"stdout","text":"epoch 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2162 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1881fe4369bc4b5c8cc759567373af4c"}},"metadata":{}},{"name":"stdout","text":"epoch 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2162 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c72952a3e29c4e9281ea6e558a308970"}},"metadata":{}}]},{"cell_type":"code","source":"print('applying the model to the test set')\n# apply the trained model to the test set\nY_actual, Y_preds = EvaluateModel(model,test_loader)","metadata":{"execution":{"iopub.status.busy":"2023-06-02T16:28:20.076556Z","iopub.execute_input":"2023-06-02T16:28:20.077250Z","iopub.status.idle":"2023-06-02T16:29:19.409760Z","shell.execute_reply.started":"2023-06-02T16:28:20.077214Z","shell.execute_reply":"2023-06-02T16:29:19.408803Z"},"trusted":true},"execution_count":168,"outputs":[{"name":"stdout","text":"applying the model to the test set\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/432 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f3cd0eaa78046ec8d67563b59344a1b"}},"metadata":{}}]},{"cell_type":"code","source":"print(\"\\nTest Accuracy : {:.3f}\".format(accuracy_score(Y_actual, Y_preds)))\nprint(\"\\nTest Macro-Accuracy : {:.3f}\".format(balanced_accuracy_score(Y_actual, Y_preds)))\nprint(\"\\nClassification Report : \")\nprint(classification_report(Y_actual, Y_preds,labels = tagmap(tagmap.get_itos()), target_names = tagmap.get_itos(), zero_division = 0))","metadata":{"execution":{"iopub.status.busy":"2023-06-02T16:29:19.411147Z","iopub.execute_input":"2023-06-02T16:29:19.411612Z","iopub.status.idle":"2023-06-02T16:29:19.481990Z","shell.execute_reply.started":"2023-06-02T16:29:19.411576Z","shell.execute_reply":"2023-06-02T16:29:19.480934Z"},"trusted":true},"execution_count":169,"outputs":[{"name":"stdout","text":"\nTest Accuracy : 0.980\n\nTest Macro-Accuracy : 0.907\n\nClassification Report : \n              precision    recall  f1-score   support\n\n           O       1.00      0.99      0.99     38323\n       B-LOC       0.92      0.94      0.93      1668\n       B-PER       0.98      0.96      0.97      1617\n       B-ORG       0.89      0.91      0.90      1661\n       I-PER       0.98      0.99      0.98      1156\n       I-ORG       0.85      0.90      0.87       835\n      B-MISC       0.83      0.83      0.83       702\n      I-MISC       0.62      0.73      0.67       216\n       I-LOC       0.82      0.91      0.87       257\n\n    accuracy                           0.98     46435\n   macro avg       0.88      0.91      0.89     46435\nweighted avg       0.98      0.98      0.98     46435\n\n","output_type":"stream"}]}]}