{"cells":[{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T18:29:04.558214Z","iopub.status.busy":"2023-06-03T18:29:04.557547Z","iopub.status.idle":"2023-06-03T18:29:04.563989Z","shell.execute_reply":"2023-06-03T18:29:04.562996Z","shell.execute_reply.started":"2023-06-03T18:29:04.558183Z"},"trusted":true},"outputs":[],"source":["#\n","# Named-entity recognition using BERT\n","# Dataset: https://www.kaggle.com/datasets/alaakhaled/conll003-englishversion\n","#\n","\n","# dependencies\n","import torch\n","import torch.optim as optim \n","from torchtext.vocab import build_vocab_from_iterator\n","from transformers import BertForTokenClassification, BertTokenizerFast\n","from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report\n","import tqdm\n","tqdmn = tqdm.notebook.tqdm"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T18:29:04.566450Z","iopub.status.busy":"2023-06-03T18:29:04.565561Z","iopub.status.idle":"2023-06-03T18:29:04.581721Z","shell.execute_reply":"2023-06-03T18:29:04.580753Z","shell.execute_reply.started":"2023-06-03T18:29:04.566419Z"},"trusted":true},"outputs":[],"source":["# hyper-parameters\n","EPOCHS = 3\n","BATCH_SIZE = 8\n","LR = 1e-5"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T18:29:04.584271Z","iopub.status.busy":"2023-06-03T18:29:04.583705Z","iopub.status.idle":"2023-06-03T18:29:04.592696Z","shell.execute_reply":"2023-06-03T18:29:04.591724Z","shell.execute_reply.started":"2023-06-03T18:29:04.584239Z"},"trusted":true},"outputs":[],"source":["# the path of the data files\n","base_path = '/kaggle/input/conll003-englishversion/'\n","\n","# use GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T18:29:04.596793Z","iopub.status.busy":"2023-06-03T18:29:04.595917Z","iopub.status.idle":"2023-06-03T18:29:04.608914Z","shell.execute_reply":"2023-06-03T18:29:04.608077Z","shell.execute_reply.started":"2023-06-03T18:29:04.596763Z"},"trusted":true},"outputs":[],"source":["# read the data files\n","def load_sentences(filepath):\n","\n","    sentences = []\n","    tokens = []\n","    pos_tags = []\n","    chunk_tags = []\n","    ner_tags = []\n","\n","    with open(filepath, 'r') as f:\n","        \n","        for line in f.readlines():\n","            \n","            if (line == ('-DOCSTART- -X- -X- O\\n') or line == '\\n'):\n","                if len(tokens) > 0:\n","                    sentences.append({'tokens': tokens, 'pos_tags': pos_tags, 'chunk_tags': chunk_tags, 'ner_tags': ner_tags})\n","                    tokens = []\n","                    pos_tags = []\n","                    chunk_tags = []\n","                    ner_tags = []\n","            else:\n","                l = line.split(' ')\n","                tokens.append(l[0])\n","                pos_tags.append(l[1])\n","                chunk_tags.append(l[2])\n","                ner_tags.append(l[3].strip('\\n'))\n","    \n","    return sentences"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T18:29:04.611401Z","iopub.status.busy":"2023-06-03T18:29:04.611021Z","iopub.status.idle":"2023-06-03T18:29:05.149499Z","shell.execute_reply":"2023-06-03T18:29:05.148373Z","shell.execute_reply.started":"2023-06-03T18:29:04.611370Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["loading data\n"]}],"source":["print('loading data')\n","train_sentences = load_sentences(base_path + 'train.txt')\n","test_sentences = load_sentences(base_path + 'test.txt')\n","valid_sentences = load_sentences(base_path + 'valid.txt')"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T18:29:05.151984Z","iopub.status.busy":"2023-06-03T18:29:05.151238Z","iopub.status.idle":"2023-06-03T18:29:05.326842Z","shell.execute_reply":"2023-06-03T18:29:05.324865Z","shell.execute_reply.started":"2023-06-03T18:29:05.151948Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Tagset size: 9\n"]}],"source":["# build tagset and tag ids\n","tags = [sentence['ner_tags'] for sentence in train_sentences]\n","tagmap = build_vocab_from_iterator(tags)\n","tagset = set([item for sublist in tags for item in sublist])\n","print('Tagset size:',len(tagset))"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T18:29:05.328806Z","iopub.status.busy":"2023-06-03T18:29:05.328318Z","iopub.status.idle":"2023-06-03T18:29:05.416060Z","shell.execute_reply":"2023-06-03T18:29:05.414998Z","shell.execute_reply.started":"2023-06-03T18:29:05.328771Z"},"trusted":true},"outputs":[],"source":["# load BERT tokenizer\n","bert_version = 'bert-base-uncased'\n","tokenizer = BertTokenizerFast.from_pretrained(bert_version)"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T18:29:05.420187Z","iopub.status.busy":"2023-06-03T18:29:05.419325Z","iopub.status.idle":"2023-06-03T18:29:05.427547Z","shell.execute_reply":"2023-06-03T18:29:05.426299Z","shell.execute_reply.started":"2023-06-03T18:29:05.420159Z"},"trusted":true},"outputs":[],"source":["# map tokens and tags to token ids and label ids\n","def align_label(tokens, labels):\n","\n","    word_ids = tokens.word_ids()\n","    previous_word_idx = None\n","    label_ids = []\n","    for word_idx in word_ids:\n","        if word_idx is None:\n","            label_ids.append(-100)\n","        elif word_idx != previous_word_idx:\n","            try:\n","                label_ids.append(tagmap[labels[word_idx]])\n","            except:\n","                label_ids.append(-100)\n","        else:\n","                label_ids.append(-100)\n","        previous_word_idx = word_idx\n","\n","    return label_ids"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T18:29:05.429749Z","iopub.status.busy":"2023-06-03T18:29:05.429128Z","iopub.status.idle":"2023-06-03T18:29:05.443030Z","shell.execute_reply":"2023-06-03T18:29:05.442086Z","shell.execute_reply.started":"2023-06-03T18:29:05.429690Z"},"trusted":true},"outputs":[],"source":["def encode(sentence):\n","    encodings = tokenizer(sentence['tokens'], truncation=True, padding='max_length', is_split_into_words=True)\n","    labels = align_label(encodings, sentence['ner_tags'])\n","    return { 'input_ids': torch.LongTensor(encodings.input_ids), 'attention_mask': torch.LongTensor(encodings.attention_mask), 'labels': torch.LongTensor(labels) }"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T18:29:05.444421Z","iopub.status.busy":"2023-06-03T18:29:05.444169Z","iopub.status.idle":"2023-06-03T18:29:20.142427Z","shell.execute_reply":"2023-06-03T18:29:20.141497Z","shell.execute_reply.started":"2023-06-03T18:29:05.444398Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["encoding data\n"]}],"source":["print('encoding data')\n","train_dataset = [encode(sentence) for sentence in train_sentences]\n","valid_dataset = [encode(sentence) for sentence in valid_sentences]\n","test_dataset = [encode(sentence) for sentence in test_sentences]"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T18:29:20.144318Z","iopub.status.busy":"2023-06-03T18:29:20.143841Z","iopub.status.idle":"2023-06-03T18:29:21.327404Z","shell.execute_reply":"2023-06-03T18:29:21.326421Z","shell.execute_reply.started":"2023-06-03T18:29:20.144283Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["initializing the model\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# initialize the model including a classification layer with num_labels classes\n","print('initializing the model')\n","model = BertForTokenClassification.from_pretrained(bert_version, num_labels=len(tagset))\n","model.to(device)\n","optimizer = optim.AdamW(params=model.parameters(), lr=LR)"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T18:29:21.329475Z","iopub.status.busy":"2023-06-03T18:29:21.329090Z","iopub.status.idle":"2023-06-03T18:29:21.408039Z","shell.execute_reply":"2023-06-03T18:29:21.407080Z","shell.execute_reply.started":"2023-06-03T18:29:21.329443Z"},"trusted":true},"outputs":[],"source":["# prepare batches of data\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T18:29:21.416389Z","iopub.status.busy":"2023-06-03T18:29:21.416051Z","iopub.status.idle":"2023-06-03T18:29:21.426718Z","shell.execute_reply":"2023-06-03T18:29:21.425725Z","shell.execute_reply.started":"2023-06-03T18:29:21.416362Z"},"trusted":true},"outputs":[],"source":["# evaluate the performance of the model\n","def EvaluateModel(model, data_loader, question_2 = False):\n","    model.eval()\n","    with torch.no_grad():\n","        Y_actual, Y_preds = [],[]\n","        for i, batch in enumerate(tqdmn(data_loader)):\n","            # move the batch tensors to the same device as the model\n","            batch = { k: v.to(device) for k, v in batch.items() }\n","            # send 'input_ids', 'attention_mask' and 'labels' to the model\n","            outputs = model(**batch)\n","            # iterate through the examples\n","            for idx, _ in enumerate(batch['labels']):\n","                # get the true values\n","                true_values_all = batch['labels'][idx]\n","                true_values = true_values_all[true_values_all != -100]\n","                # get the predicted values\n","                pred_values = torch.argmax(outputs[1], dim=2)[idx]\n","                pred_values = pred_values[true_values_all != -100]\n","                # update the lists of true answers and predictions\n","                Y_actual.append(true_values)\n","                Y_preds.append(pred_values)\n","    if question_2 == False:\n","        Y_actual = torch.cat(Y_actual)\n","        Y_preds = torch.cat(Y_preds)\n","        # Return list of actual labels, predicted labels \n","        return Y_actual.detach().cpu().numpy(), Y_preds.detach().cpu().numpy()\n","    else:\n","        # Return actual and predicted labels per sentence\n","        return [y.detach().cpu().numpy() for y in Y_actual], [y.detach().cpu().numpy() for y in Y_preds]\n","\n","        "]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T18:29:21.428601Z","iopub.status.busy":"2023-06-03T18:29:21.428234Z","iopub.status.idle":"2023-06-03T19:09:26.670944Z","shell.execute_reply":"2023-06-03T19:09:26.669817Z","shell.execute_reply.started":"2023-06-03T18:29:21.428568Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["training the model\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30b90890c424484299489228facebcef","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch 1\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"527c538f0298403aa746ece43610fe0e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1756 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2ae7e7fdec1b45b7bbbc5b8ff57bdaa8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/407 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Validation Accuracy : 0.985\n","\n","Validation Macro-Accuracy : 0.915\n","epoch 2\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d3350005c567403b8948f5f467325605","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1756 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aebf8be2448348519e3a664afd22f793","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/407 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Validation Accuracy : 0.987\n","\n","Validation Macro-Accuracy : 0.917\n","epoch 3\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c1d27824aa1497fafaf65ea2dca630a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1756 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"13ec437469d641deaf8252168e84add7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/407 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Validation Accuracy : 0.988\n","\n","Validation Macro-Accuracy : 0.929\n"]}],"source":["# train the model\n","print('training the model')\n","for epoch in tqdmn(range(EPOCHS)):\n","    model.train()\n","    print('epoch',epoch+1)\n","    # iterate through each batch of the train data\n","    for i, batch in enumerate(tqdmn(train_loader)):\n","        # move the batch tensors to the same device as the model\n","        batch = { k: v.to(device) for k, v in batch.items() }\n","        # send 'input_ids', 'attention_mask' and 'labels' to the model\n","        outputs = model(**batch)\n","        loss = outputs[0]\n","        # set the gradients to zero\n","        optimizer.zero_grad()\n","        # propagate the loss backwards\n","        loss.backward()\n","        # update the model weights\n","        optimizer.step()\n","    # calculate performence on validation set\n","    Y_actual, Y_preds = EvaluateModel(model,valid_loader)\n","    print(\"\\nValidation Accuracy : {:.3f}\".format(accuracy_score(Y_actual, Y_preds)))\n","    print(\"\\nValidation Macro-Accuracy : {:.3f}\".format(balanced_accuracy_score(Y_actual, Y_preds)))"]},{"cell_type":"code","execution_count":80,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T19:09:26.672905Z","iopub.status.busy":"2023-06-03T19:09:26.672434Z","iopub.status.idle":"2023-06-03T19:10:25.885435Z","shell.execute_reply":"2023-06-03T19:10:25.884552Z","shell.execute_reply.started":"2023-06-03T19:09:26.672870Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["applying the model to the test set\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c98175615314b589c223b7cbd31ae9c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/432 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["print('applying the model to the test set')\n","# apply the trained model to the test set\n","Y_actual, Y_preds = EvaluateModel(model,test_loader)"]},{"cell_type":"code","execution_count":81,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T19:10:25.889297Z","iopub.status.busy":"2023-06-03T19:10:25.889007Z","iopub.status.idle":"2023-06-03T19:10:25.960184Z","shell.execute_reply":"2023-06-03T19:10:25.959141Z","shell.execute_reply.started":"2023-06-03T19:10:25.889273Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Test Accuracy : 0.981\n","\n","Test Macro-Accuracy : 0.907\n","\n","Classification Report : \n","              precision    recall  f1-score   support\n","\n","           O       1.00      0.99      0.99     38323\n","       B-LOC       0.94      0.93      0.93      1668\n","       B-PER       0.98      0.97      0.97      1617\n","       B-ORG       0.89      0.91      0.90      1661\n","       I-PER       0.99      0.99      0.99      1156\n","       I-ORG       0.86      0.91      0.88       835\n","      B-MISC       0.81      0.84      0.83       702\n","       I-LOC       0.81      0.89      0.85       257\n","      I-MISC       0.69      0.74      0.71       216\n","\n","    accuracy                           0.98     46435\n","   macro avg       0.88      0.91      0.90     46435\n","weighted avg       0.98      0.98      0.98     46435\n","\n"]}],"source":["print(\"\\nTest Accuracy : {:.3f}\".format(accuracy_score(Y_actual, Y_preds)))\n","print(\"\\nTest Macro-Accuracy : {:.3f}\".format(balanced_accuracy_score(Y_actual, Y_preds)))\n","print(\"\\nClassification Report : \")\n","print(classification_report(Y_actual, Y_preds,labels = tagmap(tagmap.get_itos()), target_names = tagmap.get_itos(), zero_division = 0))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Question 2"]},{"cell_type":"code","execution_count":89,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T19:22:54.685823Z","iopub.status.busy":"2023-06-03T19:22:54.685441Z","iopub.status.idle":"2023-06-03T19:23:54.548211Z","shell.execute_reply":"2023-06-03T19:23:54.547265Z","shell.execute_reply.started":"2023-06-03T19:22:54.685794Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0f51be8205dc42c58564cbd4b1621488","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/432 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","The actual and predicted tags for the tokens of this sentence were:\n","\n","Token      Actual Tag Predicted Tag\n","SOCCER     O          O         \n","-          O          O         \n","JAPAN      B-LOC      B-LOC     \n","GET        O          O         \n","LUCKY      O          O         \n","WIN        O          O         \n",",          O          O         \n","CHINA      B-PER      B-LOC     \n","IN         O          O         \n","SURPRISE   O          O         \n","DEFEAT     O          O         \n",".          O          O         \n"]}],"source":["import numpy as np\n","\n","def find_sentence_with_at_least_one_wrong_label(Y_actual, Y_preds):\n","    for i, (preds, labels) in enumerate(zip(Y_preds, Y_actual)):\n","        num_of_wrong_labels = sum(np.array(preds) != np.array(labels))\n","        if len(labels) >= 10 and num_of_wrong_labels > 0:\n","            tokens = test_sentences[i][\"tokens\"]\n","            preds = preds[labels != -100]\n","            predictions = [tagmap.get_itos()[p] for p in preds]\n","            labels = labels[labels != -100]\n","            labels = [tagmap.get_itos()[l] for l in labels]\n","            break\n","    return tokens, predictions, labels\n","\n","Y_actual, Y_preds = EvaluateModel(model, test_loader, question_2 = True)\n","tokens, predictions, labels = find_sentence_with_at_least_one_wrong_label(Y_actual, Y_preds)\n","\n","print('\\nThe actual and predicted tags for the tokens of this sentence were:')\n","print(\"\\n{:<10} {:<10} {:<10}\".format('Token', 'Actual Tag', 'Predicted Tag'))\n","\n","for i in range(len(tokens)):\n","    print(\"{:<10} {:<10} {:<10}\".format(tokens[i], labels[i], predictions[i]))"]},{"cell_type":"code","execution_count":87,"metadata":{"execution":{"iopub.execute_input":"2023-06-03T19:19:08.903150Z","iopub.status.busy":"2023-06-03T19:19:08.902785Z","iopub.status.idle":"2023-06-03T19:19:08.959560Z","shell.execute_reply":"2023-06-03T19:19:08.958480Z","shell.execute_reply.started":"2023-06-03T19:19:08.903124Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"10baecbb7d0f4b1e8ca55bd879b9fd48","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","The actual and predicted tags for the tokens of this sentence were:\n","\n","Token      Actual Tag Predicted Tag\n","Zurich     B-ORG      B-ORG     \n","and        O          O         \n","some       O          O         \n","other      O          O         \n","insurers   O          O         \n","with       O          O         \n","big        O          O         \n","fleets     O          O         \n","of         O          O         \n","engineers  O          O         \n","are        O          O         \n","advising   O          O         \n","companies  O          O         \n","on         O          O         \n","how        O          O         \n","to         O          O         \n","fortify    O          O         \n","their      O          O         \n","properties O          O         \n",".          O          O         \n"]}],"source":["test_sentence_dict = {'tokens': ['Zurich', 'and', 'some', 'other', 'insurers', 'with', 'big', 'fleets', 'of', 'engineers', 'are', 'advising', 'companies', 'on', 'how', 'to', 'fortify', 'their', 'properties', '.'],\n","                      'pos_tags': ['NNP', 'CC', 'DT', 'JJ', 'NNS', 'IN', 'JJ', 'NNS', 'IN', 'NNS', 'VBP', 'VBG', 'NNS', 'IN', 'WRB', 'TO', 'VB', 'PRP$', 'NNS', '.'],\n","                      'chunk_tags': ['B-NP', 'O', 'B-NP', 'I-NP', 'B-NP', 'B-PP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'B-VP', 'B-VP', 'B-NP', 'B-PP', 'B-ADVP', 'B-VP', 'B-VP', 'B-NP', 'I-NP', 'O'],\n","                      'ner_tags': ['B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}\n","\n","new_test_dataset = [encode(test_sentence_dict)]\n","new_test_loader = torch.utils.data.DataLoader(new_test_dataset, batch_size=1)\n","new_Y_actual, new_Y_preds = EvaluateModel(model,new_test_loader )\n","\n","print('\\nThe actual and predicted tags for the tokens of this sentence were:')\n","print(\"\\n{:<10} {:<10} {:<10}\".format('Token', 'Actual Tag', 'Predicted Tag'))\n","\n","for i in range(len(test_sentence_dict['tokens'])):\n","    token = test_sentence_dict['tokens'][i]\n","    print(\"{:<10} {:<10} {:<10}\".format(token, tagmap.get_itos()[new_Y_actual[i].item()], tagmap.get_itos()[new_Y_preds[i].item()]))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
