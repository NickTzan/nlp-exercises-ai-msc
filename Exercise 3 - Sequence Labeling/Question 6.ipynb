{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#\n# Named-entity recognition using BERT\n# Dataset: https://www.kaggle.com/datasets/alaakhaled/conll003-englishversion\n#\n\n# dependencies\nimport torch\nimport torch.optim as optim \nfrom torchtext.vocab import build_vocab_from_iterator\nfrom transformers import BertForTokenClassification, BertTokenizerFast\nfrom sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report\nimport tqdm\ntqdmn = tqdm.notebook.tqdm","metadata":{"execution":{"iopub.status.busy":"2023-06-03T19:27:19.309173Z","iopub.execute_input":"2023-06-03T19:27:19.309545Z","iopub.status.idle":"2023-06-03T19:27:19.315819Z","shell.execute_reply.started":"2023-06-03T19:27:19.309516Z","shell.execute_reply":"2023-06-03T19:27:19.314751Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"# hyper-parameters\nEPOCHS = 3\nBATCH_SIZE = 8\nLR = 1e-5","metadata":{"execution":{"iopub.status.busy":"2023-06-03T19:27:19.317892Z","iopub.execute_input":"2023-06-03T19:27:19.318330Z","iopub.status.idle":"2023-06-03T19:27:19.329150Z","shell.execute_reply.started":"2023-06-03T19:27:19.318266Z","shell.execute_reply":"2023-06-03T19:27:19.328302Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"# the path of the data files\nbase_path = '/kaggle/input/conll003-englishversion/'\n\n# use GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-06-03T19:27:19.330427Z","iopub.execute_input":"2023-06-03T19:27:19.331027Z","iopub.status.idle":"2023-06-03T19:27:19.339059Z","shell.execute_reply.started":"2023-06-03T19:27:19.330995Z","shell.execute_reply":"2023-06-03T19:27:19.338068Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"# read the data files\ndef load_sentences(filepath):\n\n    sentences = []\n    tokens = []\n    pos_tags = []\n    chunk_tags = []\n    ner_tags = []\n\n    with open(filepath, 'r') as f:\n        \n        for line in f.readlines():\n            \n            if (line == ('-DOCSTART- -X- -X- O\\n') or line == '\\n'):\n                if len(tokens) > 0:\n                    sentences.append({'tokens': tokens, 'pos_tags': pos_tags, 'chunk_tags': chunk_tags, 'ner_tags': ner_tags})\n                    tokens = []\n                    pos_tags = []\n                    chunk_tags = []\n                    ner_tags = []\n            else:\n                l = line.split(' ')\n                tokens.append(l[0])\n                pos_tags.append(l[1])\n                chunk_tags.append(l[2])\n                ner_tags.append(l[3].strip('\\n'))\n    \n    return sentences","metadata":{"execution":{"iopub.status.busy":"2023-06-03T19:27:19.341451Z","iopub.execute_input":"2023-06-03T19:27:19.342328Z","iopub.status.idle":"2023-06-03T19:27:19.351498Z","shell.execute_reply.started":"2023-06-03T19:27:19.342297Z","shell.execute_reply":"2023-06-03T19:27:19.350521Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"print('loading data')\ntrain_sentences = load_sentences(base_path + 'train.txt')\ntest_sentences = load_sentences(base_path + 'test.txt')\nvalid_sentences = load_sentences(base_path + 'valid.txt')","metadata":{"execution":{"iopub.status.busy":"2023-06-03T19:27:19.353052Z","iopub.execute_input":"2023-06-03T19:27:19.353874Z","iopub.status.idle":"2023-06-03T19:27:19.822205Z","shell.execute_reply.started":"2023-06-03T19:27:19.353836Z","shell.execute_reply":"2023-06-03T19:27:19.821261Z"},"trusted":true},"execution_count":94,"outputs":[{"name":"stdout","text":"loading data\n","output_type":"stream"}]},{"cell_type":"markdown","source":"When specifying the tags that are going to be used we replace the 'ner_tags' with 'pos_tags' in this block of code.","metadata":{}},{"cell_type":"code","source":"# build tagset and tag ids\ntags = [sentence['pos_tags'] for sentence in train_sentences]\ntagmap = build_vocab_from_iterator(tags)\ntagset = set([item for sublist in tags for item in sublist])\nprint('Tagset size:',len(tagset))","metadata":{"execution":{"iopub.status.busy":"2023-06-03T19:27:19.823720Z","iopub.execute_input":"2023-06-03T19:27:19.824068Z","iopub.status.idle":"2023-06-03T19:27:19.990148Z","shell.execute_reply.started":"2023-06-03T19:27:19.824036Z","shell.execute_reply":"2023-06-03T19:27:19.988941Z"},"trusted":true},"execution_count":95,"outputs":[{"name":"stdout","text":"Tagset size: 45\n","output_type":"stream"}]},{"cell_type":"code","source":"# load BERT tokenizer\nbert_version = 'bert-base-uncased'\ntokenizer = BertTokenizerFast.from_pretrained(bert_version)","metadata":{"execution":{"iopub.status.busy":"2023-06-03T19:27:19.991994Z","iopub.execute_input":"2023-06-03T19:27:19.992377Z","iopub.status.idle":"2023-06-03T19:27:20.161595Z","shell.execute_reply.started":"2023-06-03T19:27:19.992343Z","shell.execute_reply":"2023-06-03T19:27:20.160658Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"# map tokens and tags to token ids and label ids\ndef align_label(tokens, labels):\n\n    word_ids = tokens.word_ids()\n    previous_word_idx = None\n    label_ids = []\n    for word_idx in word_ids:\n        if word_idx is None:\n            label_ids.append(-100)\n        elif word_idx != previous_word_idx:\n            try:\n                label_ids.append(tagmap[labels[word_idx]])\n            except:\n                label_ids.append(-100)\n        else:\n                label_ids.append(-100)\n        previous_word_idx = word_idx\n\n    return label_ids","metadata":{"execution":{"iopub.status.busy":"2023-06-03T19:27:20.167590Z","iopub.execute_input":"2023-06-03T19:27:20.167899Z","iopub.status.idle":"2023-06-03T19:27:20.174205Z","shell.execute_reply.started":"2023-06-03T19:27:20.167874Z","shell.execute_reply":"2023-06-03T19:27:20.173107Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"markdown","source":"In the next block the ner_tags should also be replaced with pos_tags.","metadata":{}},{"cell_type":"code","source":"def encode(sentence):\n    encodings = tokenizer(sentence['tokens'], truncation=True, padding='max_length', is_split_into_words=True)\n    labels = align_label(encodings, sentence['pos_tags'])\n    return { 'input_ids': torch.LongTensor(encodings.input_ids), 'attention_mask': torch.LongTensor(encodings.attention_mask), 'labels': torch.LongTensor(labels) }","metadata":{"execution":{"iopub.status.busy":"2023-06-03T19:27:20.178051Z","iopub.execute_input":"2023-06-03T19:27:20.178742Z","iopub.status.idle":"2023-06-03T19:27:20.186487Z","shell.execute_reply.started":"2023-06-03T19:27:20.178708Z","shell.execute_reply":"2023-06-03T19:27:20.185546Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"print('encoding data')\ntrain_dataset = [encode(sentence) for sentence in train_sentences]\nvalid_dataset = [encode(sentence) for sentence in valid_sentences]\ntest_dataset = [encode(sentence) for sentence in test_sentences]","metadata":{"execution":{"iopub.status.busy":"2023-06-03T19:27:20.188150Z","iopub.execute_input":"2023-06-03T19:27:20.188904Z","iopub.status.idle":"2023-06-03T19:27:34.329112Z","shell.execute_reply.started":"2023-06-03T19:27:20.188870Z","shell.execute_reply":"2023-06-03T19:27:34.328054Z"},"trusted":true},"execution_count":99,"outputs":[{"name":"stdout","text":"encoding data\n","output_type":"stream"}]},{"cell_type":"code","source":"# initialize the model including a classification layer with num_labels classes\nprint('initializing the model')\nmodel = BertForTokenClassification.from_pretrained(bert_version, num_labels=len(tagset))\nmodel.to(device)\noptimizer = optim.AdamW(params=model.parameters(), lr=LR)","metadata":{"execution":{"iopub.status.busy":"2023-06-03T19:27:34.330849Z","iopub.execute_input":"2023-06-03T19:27:34.331236Z","iopub.status.idle":"2023-06-03T19:27:35.458855Z","shell.execute_reply.started":"2023-06-03T19:27:34.331191Z","shell.execute_reply":"2023-06-03T19:27:35.457897Z"},"trusted":true},"execution_count":100,"outputs":[{"name":"stdout","text":"initializing the model\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# prepare batches of data\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-06-03T19:27:35.460497Z","iopub.execute_input":"2023-06-03T19:27:35.460882Z","iopub.status.idle":"2023-06-03T19:27:35.540191Z","shell.execute_reply.started":"2023-06-03T19:27:35.460848Z","shell.execute_reply":"2023-06-03T19:27:35.539222Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"# evaluate the performance of the model\ndef EvaluateModel(model, data_loader, question_2 = False):\n    model.eval()\n    with torch.no_grad():\n        Y_actual, Y_preds = [],[]\n        for i, batch in enumerate(tqdmn(data_loader)):\n            # move the batch tensors to the same device as the model\n            batch = { k: v.to(device) for k, v in batch.items() }\n            # send 'input_ids', 'attention_mask' and 'labels' to the model\n            outputs = model(**batch)\n            # iterate through the examples\n            for idx, _ in enumerate(batch['labels']):\n                # get the true values\n                true_values_all = batch['labels'][idx]\n                true_values = true_values_all[true_values_all != -100]\n                # get the predicted values\n                pred_values = torch.argmax(outputs[1], dim=2)[idx]\n                pred_values = pred_values[true_values_all != -100]\n                # update the lists of true answers and predictions\n                Y_actual.append(true_values)\n                Y_preds.append(pred_values)\n    if question_2 == False:\n        Y_actual = torch.cat(Y_actual)\n        Y_preds = torch.cat(Y_preds)\n        # Return list of actual labels, predicted labels \n        return Y_actual.detach().cpu().numpy(), Y_preds.detach().cpu().numpy()\n    else:\n        # Return actual and predicted labels per sentence\n        return [y.detach().cpu().numpy() for y in Y_actual], [y.detach().cpu().numpy() for y in Y_preds]","metadata":{"execution":{"iopub.status.busy":"2023-06-03T19:27:35.544350Z","iopub.execute_input":"2023-06-03T19:27:35.544680Z","iopub.status.idle":"2023-06-03T19:27:35.557096Z","shell.execute_reply.started":"2023-06-03T19:27:35.544654Z","shell.execute_reply":"2023-06-03T19:27:35.556101Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"# train the model\nprint('training the model')\nfor epoch in tqdmn(range(EPOCHS)):\n    model.train()\n    print('epoch',epoch+1)\n    # iterate through each batch of the train data\n    for i, batch in enumerate(tqdmn(train_loader)):\n        # move the batch tensors to the same device as the model\n        batch = { k: v.to(device) for k, v in batch.items() }\n        # send 'input_ids', 'attention_mask' and 'labels' to the model\n        outputs = model(**batch)\n        loss = outputs[0]\n        # set the gradients to zero\n        optimizer.zero_grad()\n        # propagate the loss backwards\n        loss.backward()\n        # update the model weights\n        optimizer.step()\n    # calculate performence on validation set\n    Y_actual, Y_preds = EvaluateModel(model,valid_loader)\n    print(\"\\nValidation Accuracy : {:.3f}\".format(accuracy_score(Y_actual, Y_preds)))\n    print(\"\\nValidation Macro-Accuracy : {:.3f}\".format(balanced_accuracy_score(Y_actual, Y_preds)))","metadata":{"execution":{"iopub.status.busy":"2023-06-03T19:27:35.558318Z","iopub.execute_input":"2023-06-03T19:27:35.559273Z","iopub.status.idle":"2023-06-03T20:07:40.741961Z","shell.execute_reply.started":"2023-06-03T19:27:35.559242Z","shell.execute_reply":"2023-06-03T20:07:40.740814Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stdout","text":"training the model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e28bc8cd9792471fb4c0b93d43563679"}},"metadata":{}},{"name":"stdout","text":"epoch 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1756 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e418e9ea5db4b3a984a37932a6e562c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/407 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7598f0143e64023948c3cb41c1fec9c"}},"metadata":{}},{"name":"stdout","text":"\nValidation Accuracy : 0.934\n\nValidation Macro-Accuracy : 0.733\nepoch 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1756 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aec36cf4710c43c8a8b99c2894ffd646"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/407 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca3ee425739844dfa768af9fbe06ba0e"}},"metadata":{}},{"name":"stdout","text":"\nValidation Accuracy : 0.943\n\nValidation Macro-Accuracy : 0.804\nepoch 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1756 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9e21a79458a4f218bdcd4f3a627049a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/407 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a25f943bc1c43fe9d01e6744c6353a9"}},"metadata":{}},{"name":"stdout","text":"\nValidation Accuracy : 0.947\n\nValidation Macro-Accuracy : 0.829\n","output_type":"stream"}]},{"cell_type":"code","source":"print('applying the model to the test set')\n# apply the trained model to the test set\nY_actual, Y_preds = EvaluateModel(model,test_loader)","metadata":{"execution":{"iopub.status.busy":"2023-06-03T20:07:40.744042Z","iopub.execute_input":"2023-06-03T20:07:40.744478Z","iopub.status.idle":"2023-06-03T20:08:39.778075Z","shell.execute_reply.started":"2023-06-03T20:07:40.744441Z","shell.execute_reply":"2023-06-03T20:08:39.777072Z"},"trusted":true},"execution_count":104,"outputs":[{"name":"stdout","text":"applying the model to the test set\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/432 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9bbd46b08ff477c98b87ee1ada0e52b"}},"metadata":{}}]},{"cell_type":"code","source":"print(\"\\nTest Accuracy : {:.3f}\".format(accuracy_score(Y_actual, Y_preds)))\nprint(\"\\nTest Macro-Accuracy : {:.3f}\".format(balanced_accuracy_score(Y_actual, Y_preds)))\nprint(\"\\nClassification Report : \")\nprint(classification_report(Y_actual, Y_preds,labels = tagmap(tagmap.get_itos()), target_names = tagmap.get_itos(), zero_division = 0))","metadata":{"execution":{"iopub.status.busy":"2023-06-03T20:08:39.779621Z","iopub.execute_input":"2023-06-03T20:08:39.780055Z","iopub.status.idle":"2023-06-03T20:08:39.905305Z","shell.execute_reply.started":"2023-06-03T20:08:39.780015Z","shell.execute_reply":"2023-06-03T20:08:39.903974Z"},"trusted":true},"execution_count":105,"outputs":[{"name":"stdout","text":"\nTest Accuracy : 0.941\n\nTest Macro-Accuracy : 0.846\n\nClassification Report : \n              precision    recall  f1-score   support\n\n         NNP       0.90      0.93      0.91      8595\n          NN       0.90      0.88      0.89      4931\n          CD       0.97      1.00      0.98      5962\n          IN       0.98      0.99      0.99      4018\n          DT       0.99      0.99      0.99      2799\n          JJ       0.86      0.82      0.84      2393\n         NNS       0.92      0.93      0.93      2174\n         VBD       0.94      0.95      0.94      1699\n           .       1.00      1.00      1.00      1630\n           ,       1.00      1.00      1.00      1637\n          VB       0.92      0.90      0.91       933\n         VBN       0.88      0.86      0.87       866\n          RB       0.90      0.85      0.87       888\n          CC       1.00      0.99      1.00       765\n          TO       1.00      1.00      1.00       818\n         PRP       0.99      0.97      0.98       605\n           (       1.00      1.00      1.00       688\n           )       1.00      1.00      1.00       686\n         VBG       0.92      0.89      0.90       484\n         VBZ       0.91      0.84      0.87       502\n           :       1.00      1.00      1.00       599\n           \"       1.00      1.00      1.00       421\n         POS       0.96      0.97      0.97       347\n        PRP$       1.00      1.00      1.00       296\n         VBP       0.88      0.89      0.88       331\n          MD       0.99      0.99      0.99       268\n        NNPS       0.61      0.42      0.50       160\n          RP       0.76      0.66      0.71       106\n          WP       1.00      0.99      1.00       114\n         WDT       0.96      0.94      0.95       108\n         SYM       0.93      0.98      0.96       117\n           $       0.99      0.99      0.99        94\n         WRB       1.00      1.00      1.00        74\n         JJR       0.78      0.83      0.80        92\n         JJS       0.96      0.88      0.92        56\n          FW       0.38      0.33      0.35        33\n         RBR       0.71      0.56      0.62        43\n          EX       0.97      0.97      0.97        34\n          ''       0.67      1.00      0.80        14\n         RBS       0.89      0.89      0.89         9\n         PDT       0.50      0.14      0.22         7\n          UH       0.00      0.00      0.00         7\n         WP$       1.00      1.00      1.00         9\n          LS       0.00      0.00      0.00        23\n      NN|SYM       0.00      0.00      0.00         0\n\n   micro avg       0.94      0.94      0.94     46435\n   macro avg       0.84      0.83      0.83     46435\nweighted avg       0.94      0.94      0.94     46435\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\ndef find_sentence_with_at_least_one_wrong_label(Y_actual, Y_preds):\n    for i, (preds, labels) in enumerate(zip(Y_preds, Y_actual)):\n        num_of_wrong_labels = sum(np.array(preds) != np.array(labels))\n        if len(labels) >= 10 and num_of_wrong_labels > 0:\n            tokens = test_sentences[i][\"tokens\"]\n            preds = preds[labels != -100]\n            predictions = [tagmap.get_itos()[p] for p in preds]\n            labels = labels[labels != -100]\n            labels = [tagmap.get_itos()[l] for l in labels]\n            break\n    return tokens, predictions, labels\n\nY_actual, Y_preds = EvaluateModel(model, test_loader, question_2 = True)\ntokens, predictions, labels = find_sentence_with_at_least_one_wrong_label(Y_actual, Y_preds)\n\nprint('\\nThe actual and predicted tags for the tokens of this sentence were:')\nprint(\"\\n{:<10} {:<10} {:<10}\".format('Token', 'Actual Tag', 'Predicted Tag'))\n\nfor i in range(len(tokens)):\n    print(\"{:<10} {:<10} {:<10}\".format(tokens[i], labels[i], predictions[i]))","metadata":{"execution":{"iopub.status.busy":"2023-06-03T20:08:39.907027Z","iopub.execute_input":"2023-06-03T20:08:39.907654Z","iopub.status.idle":"2023-06-03T20:09:39.114661Z","shell.execute_reply.started":"2023-06-03T20:08:39.907597Z","shell.execute_reply":"2023-06-03T20:09:39.113701Z"},"trusted":true},"execution_count":106,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/432 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66adcf7ba5bb420f9e2df56bb4c38845"}},"metadata":{}},{"name":"stdout","text":"\nThe actual and predicted tags for the tokens of this sentence were:\n\nToken      Actual Tag Predicted Tag\nSOCCER     NN         NN        \n-          :          :         \nJAPAN      NNP        NNP       \nGET        VB         NNP       \nLUCKY      NNP        NNP       \nWIN        NNP        NNP       \n,          ,          ,         \nCHINA      NNP        NNP       \nIN         IN         IN        \nSURPRISE   DT         NNP       \nDEFEAT     NN         NN        \n.          .          .         \n","output_type":"stream"}]},{"cell_type":"code","source":"test_sentence_dict = {'tokens': ['Zurich', 'and', 'some', 'other', 'insurers', 'with', 'big', 'fleets', 'of', 'engineers', 'are', 'advising', 'companies', 'on', 'how', 'to', 'fortify', 'their', 'properties', '.'],\n                      'pos_tags': ['NNP', 'CC', 'DT', 'JJ', 'NNS', 'IN', 'JJ', 'NNS', 'IN', 'NNS', 'VBP', 'VBG', 'NNS', 'IN', 'WRB', 'TO', 'VB', 'PRP$', 'NNS', '.'],\n                      'chunk_tags': ['B-NP', 'O', 'B-NP', 'I-NP', 'B-NP', 'B-PP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'B-VP', 'B-VP', 'B-NP', 'B-PP', 'B-ADVP', 'B-VP', 'B-VP', 'B-NP', 'I-NP', 'O'],\n                      'ner_tags': ['B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']}\n\nnew_test_dataset = [encode(test_sentence_dict)]\nnew_test_loader = torch.utils.data.DataLoader(new_test_dataset, batch_size=1)\nnew_Y_actual, new_Y_preds = EvaluateModel(model,new_test_loader )\n\nprint('\\nThe actual and predicted tags for the tokens of this sentence were:')\nprint(\"\\n{:<10} {:<10} {:<10}\".format('Token', 'Actual Tag', 'Predicted Tag'))\n\nfor i in range(len(test_sentence_dict['tokens'])):\n    token = test_sentence_dict['tokens'][i]\n    print(\"{:<10} {:<10} {:<10}\".format(token, tagmap.get_itos()[new_Y_actual[i].item()], tagmap.get_itos()[new_Y_preds[i].item()]))","metadata":{"execution":{"iopub.status.busy":"2023-06-03T20:09:39.116263Z","iopub.execute_input":"2023-06-03T20:09:39.116878Z","iopub.status.idle":"2023-06-03T20:09:39.172868Z","shell.execute_reply.started":"2023-06-03T20:09:39.116845Z","shell.execute_reply":"2023-06-03T20:09:39.171843Z"},"trusted":true},"execution_count":107,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40253cc8aca8429c9846e68347c824d4"}},"metadata":{}},{"name":"stdout","text":"\nThe actual and predicted tags for the tokens of this sentence were:\n\nToken      Actual Tag Predicted Tag\nZurich     NNP        NNP       \nand        CC         CC        \nsome       DT         DT        \nother      JJ         JJ        \ninsurers   NNS        NNS       \nwith       IN         IN        \nbig        JJ         JJ        \nfleets     NNS        NNS       \nof         IN         IN        \nengineers  NNS        NNS       \nare        VBP        VBP       \nadvising   VBG        VBG       \ncompanies  NNS        NNS       \non         IN         IN        \nhow        WRB        WRB       \nto         TO         TO        \nfortify    VB         VB        \ntheir      PRP$       PRP$      \nproperties NNS        NNS       \n.          .          .         \n","output_type":"stream"}]}]}